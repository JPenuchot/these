\documentclass[../main]{subfiles}

\begin{document}

\section{
  Sample use case
}

This example covers a short yet practical example of ctbench usage. We want to
calculate the sum of a series of integers known at compile-time, using a type
template to store unsigned integer values at compile-time.

We will be comparing the compile-time performance of two implementations:
one based on a recursive function template,
and another one based on \cpp11 parameter pack expansion.

First we need to include \lstinline{utility} to instantiate our benchmark
according to the size parameter using \lstinline{std::make_index_sequence}, and
define the compile-time container type for an unsigned integer:

\begin{lstlisting}[
  language=C++
]{}
#include <utility>

/// Compile-time std::size_t
template <std::size_t N> struct ct_uint_t {
  static constexpr std::size_t value = N;
};
\end{lstlisting}

The first version of the metaprogram in listing \ref{lst:recursive-sum} is based on a recursive template function,
which we believe to offer poor compile-time performance due to the many
template instantiation it may trigger.
The version in listing \ref{lst:expansion-sum} relies on \cpp11
parameter pack expansion, which we believe to offer much better scaling.

\begin{lstlisting}[
  language=C++,,
  caption=Compile-time sum: recursive implementation,
  label=lst:recursive-sum
]{}
template <typename... Ts> constexpr auto sum();

template <> constexpr auto sum() {
  return ct_uint_t<0>{};
}
template <typename T> constexpr auto sum(T const &) {
  return T{};
}

template <typename T, typename... Ts>
constexpr auto sum(T const &, Ts const &...tl) {
  return ct_uint_t<T::value +
                   decltype(sum(tl...))::value>{};
}
\end{lstlisting}

\clearpage%

\begin{lstlisting}[
  language=C++,
  caption=Compile-time sum: parameter pack implementation,
  label=lst:expansion-sum
]{}
template <typename... Ts> constexpr auto sum();

template <> constexpr auto sum() {
  return ct_uint_t<0>{};
}

template <typename... Ts>
constexpr auto sum(Ts const &...) {
  return ct_uint_t<(Ts::value + ... + 0)>{};
}

\end{lstlisting}

\begin{lstlisting}[
  language=C++,
  caption=Benchmark driver code,
  label=lst:ctbench-driver-code
]{}
template <typename = void> constexpr auto foo() {
  return
      []<std::size_t... Is>(std::index_sequence<Is...>) {
        return sum(ct_uint_t<Is>{}...);
      }(std::make_index_sequence<BENCHMARK_SIZE>{});
}

constexpr std::size_t result = decltype(foo())::value;
\end{lstlisting}

Both versions share the same interface, and thus the same driver code in
listing \ref{lst:ctbench-driver-code} is the same for both cases.
It takes care of scaling the benchmark according to \lstinline{BENCHMARK_SIZE},
which is defined by \ctbench through the CMake API.

We may now declare the benchmark targets at the desired sizes and
repetition number, as well as the graph target to draw and compare the results.
This is done through the CMake code shown in listing
\ref{lst:ctbench-bench-decl}.

The configuration file for the graph generator is stored in
\lstinline{compare-all.json}.
It contains parameters such as the size of the benchmark, output formats,
axis labels, and JSON pointers to designate the values to observe as shown in
listing \ref{lst:ctbench-graph-config}.
In this case, it selects the \lstinline{compare_by} plotter to generate one
plot for each value pair designated by the JSON pointers in
\lstinline{key_ptrs}, namely \lstinline{/name} and \lstinline{/args/detail}.
The first pointer designates the LLVM timer name, and the second *may* refer to
metadata such a \cpp symbol, or a \cpp source filename. The \lstinline{demangle}
option may be used to demangle \cpp symbols using LLVM.

\begin{lstlisting}[
  language=CMake,
  caption=ctbench benchmark and graph declarations,
  label=lst:ctbench-bench-decl
]{}
ctbench_add_benchmark(variadic_sum.expansion
  variadic_sum/expansion.cpp ${BENCH_RANGE} ${BENCH_REP})
ctbench_add_benchmark(variadic_sum.recursive
  variadic_sum/recursive.cpp ${BENCH_RANGE} ${BENCH_REP})

ctbench_add_graph(variadic_sum-graph compare-all.json
  variadic_sum.expansion variadic_sum.recursive)
\end{lstlisting}

\clearpage%

\begin{lstlisting}[
  language=JSON,
  caption=ctbench graph configuration,
  label=lst:ctbench-graph-config
]{}
{
  "plotter": "compare_by",
  "legend_title": "Timings",
  "x_label": "Benchmark size factor",
  "y_label": "Time (microsecond)",
  "draw_average": true,
  "demangle": false,
  "draw_points": false,
  "width": 800,
  "height": 400,
  "key_ptrs": ["/name", "/args/detail"],
  "value_ptr": "/dur",
  "plot_file_extensions": [".svg"]
}
\end{lstlisting}

The result is a series of graphs, each one designating a particular timer event,
specific to a source or a symbol whenever it is possible (ie. whenever metadata
is present in the \lstinline{/args/detail} value of a timer event). Each graph
compares the evolution of these timer events in function of the benchmark size.

The following graphs were generated on a Lenovo T470 with an Intel i5 6300U and
8GB of RAM. The compiler is Clang 14.0.6, and Pyperf \cite{pyperf} was used
to turn off CPU frequency scaling to improve measurement precision.

\begin{figure}[h]
\fontsize{8}{10}\selectfont
\includesvg[width=\textwidth]{images/InstantiateFunction/foovoid}
\caption{InstantiateFunction measurement for the foo<void> symbol}
\label{fig:instantiate-foo-void}
\end{figure}

\begin{figure}[h]
\fontsize{8}{10}\selectfont
\includesvg[width=\textwidth]{images/timer-aggregates}
\caption{Timer aggregate measurements}
\label{fig:total-timers}
\end{figure}

The first timer we want to look at in figure \ref{fig:total-timers} is
ExecuteCompiler, which measures the total compilation time.
Starting from there we can go down in the timer event hierarchy to take a look
at frontend and backend execution times, and finally InstantiateFunction as
it makes up for most of the Frontend execution time.

The backend is not being impacted here, supposedly because this is purely a
compile-time program and the output program is empty. However this might not be
the case for all metaprograms, and metaprograms might have different impacts on
the backend as they may generate programs in different ways (ie. generate more
symbols, larger symbols, more data structures, etc.).

Finally, we can take a look at \lstinline{InstantiateFunction/foovoid.svg},
shown in figure \ref{fig:instantiate-foo-void}, which measures the
InstantiateFunction event time specifically for the \lstinline{foo<void>()}
symbol, which is our driver template function. Using Perfetto UI to look at the
timer event hierarchy, we determined that this event englobes all the events
that grow with the instantiation size.

\end{document}
