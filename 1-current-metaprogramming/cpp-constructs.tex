\documentclass[../main]{subfiles}
\begin{document}

\section{
  \cpp language constructs for metaprogramming
}

Templates are an interesting technique for generative programming. As they
are Turing-complete \cite{unruh:1994}, one can design a set of
\textbf{template metaprograms} \cite{abrahams:2004} allowing the compiler
to perform arbitrary computation at compile time and generating temporary
\cpp code fragment as an output.
The resulting temporary source code is then
merged with the rest of the source code and finally processed by the classic
compilation process.
\\

Listing \ref{lst:basic-tmp} shows basic principles of \cpp template
metaprogramming. The \lstinline{fibonacci_t} type template accepts an
integer called $N$, and exposes the $N\textsuperscript{th}$ element
of the Fibonacci series as its \lstinline{value} static member.
The template has 3 definitions:
a generic one to calculate elements for $N > 1$,
and two specializations for elements of ranks $0$ and $1$.

\clearpage

\begin{lstlisting}[
  language=C++,
  caption=Example of compile time computation using C++ templates,
  label=lst:basic-tmp
]{}
template <unsigned N> struct fibonacci_t;

template <unsigned N> struct fibonacci_t {
  static constexpr unsigned value =
      fibonacci_t<N - 2>::value + fibonacci_t<N - 1>::value;
};

// Specialization for cases 0 and 1
template <> struct fibonacci_t<0> {
  static constexpr unsigned value = 0;
};

template <> struct fibonacci_t<1> {
  static constexpr unsigned value = 1;
};

std::array<int, fibonacci_t<5>::value> some_array;
\end{lstlisting}

Due to the fact that template code generation is performed at compile time,
it is limited to the use of constants and supports pattern-matching and
recursion thanks to template partial specialization. It can then be looked
at as a pure functional language \cite{haeri:2012}.
The execution of metaprograms by the compiler enables libraries to implement
domain-specific optimizations.
\\

Metaprograms can be seen as programs that take code as input and/or output.
This distinction will be important to explain the work presented in
this thesis, as it focuses a lot on methods to translate
compile time compute results into \cpp programs.

\subsection{
  Different kinds of templates
}

\cpp templates offer ways to output code for both data structures
and functions.

\begin{itemize}
\item \textbf{Type templates}, ... % TODO: petite description...

\begin{lstlisting}[language=c++]{}
template <typename T> struct named_value_t {
  std::string name;
  T value;
};
\end{lstlisting}

\item \textbf{Type aliases}, ... % TODO: petite description...

\begin{lstlisting}[language=c++]{}
template <typename T>
using nested_named_value_t =
    named_value_t<named_value_t<T>>;
\end{lstlisting}

\item \textbf{Function templates}, ... % TODO: petite description...

\begin{lstlisting}[language=c++]{}
/// Returns a value annotated with
/// its string representation
template <typename T>
named_value_t<T> make_named_value(T value) {
  return named_value_t<T>(std::to_string(value),
                          std::move(value));
}
\end{lstlisting}

\item \textbf{Variable templates}, ... % TODO: petite description...

\begin{lstlisting}[language=c++]{}
/// Returns the default value of T annotated with
/// its string representation
template <typename T>
named_value_t<T> annotated_default_v =
    make_named_value(T{});

named_value_t<int> val = annotated_default_v<int>;
\end{lstlisting}

\end{itemize}

\subsection{
  Different kinds of parameters
}

\begin{itemize}
\item Type parameters
\item \gls{nttp}
\item Parameter packs
\end{itemize}

\subsection{
  Advanced \cpp template mechanisms
}

\begin{itemize}
\item \gls{sfinae}
\item Template specialization
\item Parameter pack expansion
\end{itemize}

\subsection{
  Compile time logic
}

\begin{itemize}
\item Computation using types % TODO: Remplir
\item Computation using values % TODO: Remplir
\item \gls{constexpr} functions % TODO: Remplir
\item \gls{constexpr} memory allocation % TODO: Remplir
\end{itemize}

The use of \gls{constexpr} functions for compile time programming is preferable
for many reasons: familiar to most \cpp developers (and therefore more
maintainable), it allows the use of types to enforce semantics properly
as opposed to type-based metaprogramming, and it scales much better than
\gls{tmp}.

\section{
  Metaprogramming libraries
}
\label{lbl:meta-libraries}

As previously said \cpp templates can be seen as a functional language.
Over time a range of libraries emerged, aiming to provide functionalities
similar to regular language such as containers and algorithms for use in
template metaprograms. Notable examples of such libraries are MPL\cite{mpl},
Brigand\cite{brigand}, and mp11 \cite{mp11}.

% TODO: Ajouter un exemple type qui se fait avec les 3 biblios

Libraries for more specific uses were also implemented, such as
Spirit\cite{spirit} for writing parsers (not for compile time parsing),
\gls{ctre} \cite{ctre} for compiling regular expressions,
and \gls{ctpg} \cite{ctpg} for generating LR1 parsers
(also not for compile time parsing).

% TODO: Des p'tits exemples

The benefits of metaprogrammed libraries are:

\begin{itemize}

\item \textbf{Performance}: notably in the case of \gls{ctre}.
Regular expressions are usually interpreted at runtime,
which adds a measurable overhead to text processing.
\gls{ctre} shows leading performance, on par with Rust's regex library
which also works by compiling regular expressions.

\item \textbf{Language integration}: since these are \cpp libraries,
their APIs can take advantage of \cpp operator overloading and lambdas.
In \gls{ctpg}, these are used to provide a domain-specific language that is close to
what parser generators like YACC or Bison provide,
though it is still regular \cpp code which can be put inside any function body.
Using a \cpp API makes these libraries easier to learn
as the syntax is already familiar to their users.

\item \textbf{Streamlined toolchain}: as they only require to be included as headers.
This avoids complicating compilation toolchains by requiring additional programs
to be installed and integrated to the build system.

\end{itemize}

All these examples show that metaprogramming is not just a gimmick.
There is enough interest in leveraging metaprogramming
for generic programming that many frameworks, libraries, or languages
have been developed around this paradigm and maintained sometimes
for more than a decade. Its adoption in languages like Braid, Julia, Terra,
Rust, or Dlang shows that it is not limited to \cpp.

However, most of generic libraries and frameworks that are developed
and maintained today are based on \cpp, and \cpp itself is likely to
evolve to provide more ways to generate programs as shown by the recent
standard proposal for Scalable Reflection in \cpp \cite{scalable-reflection}.
\section{
  Applications of metaprogramming for HPC
}

There are many \cpp \gls{hpc} libraries that use metaprogramming to achieve
high levels of performance while being generic and proposing high level APIs.
This subsection aims to provide an overview of notable libraries that fit this
description as well as recent efforts that are still under development.

\begin{itemize}

\item
\textbf{Eigen} \cite{eigen} is the first major \cpp library to implement
Expression templates for the generation of high performance math computing.
Expression templates is a \cpp design pattern that consists in representing
math expressions with type template trees. We will discuss them later
in \ref{lbl:expression-level-metaprogramming}.

\begin{lstlisting}[
  language=c++
]{}
#include <Eigen/Dense>
#include <iostream>

using Eigen::MatrixXd;
using Eigen::VectorXd;

int main() {
  MatrixXd m = MatrixXd::Random(3, 3);
  m = (m + MatrixXd::Constant(3, 3, 1.2)) * 50;
  std::cout << "m =" << std::endl << m << std::endl;
  VectorXd v(3);
  v << 1, 2, 3;
  std::cout << "m * v =" << std::endl
            << m * v << std::endl;
}
\end{lstlisting}

\item
\textbf{Blaze} \cite{blazelib} is a successor of Eigen that implements so-called
"Smart Expression Templates" which extends upon the concept of
expression templates implemented by Eigen. It aims to provide a more performant
and extensible \gls{hpc} library. However, Eigen is not set in stone
and its designed has since been updated.

\begin{lstlisting}[
  language=c++
]{}
#include <blaze/Math.h>
#include <iostream>

using blaze::DynamicVector;
using blaze::StaticVector;

int main() {
  StaticVector<int, 3UL> a{4, -2, 5};
  DynamicVector<int> b(3UL);

  b[0] = 2;
  b[1] = 5;
  b[2] = -3;

  DynamicVector<int> c = a + b;

  std::cout << "c =\n" << c << "\n";
}
\end{lstlisting}

\item
\textbf{NT2} \cite{nt2} is a research project that aims to provide a complete
numerical toolbox that leverages metaprogramming to develop portable \gls{hpc}
applications with a Matlab-like interface while still achieving state-of-the-art
computing performance.

\begin{lstlisting}[
  language=c++
]{}
#include <nt2/include/functions/ones.hpp>
#include <nt2/table.hpp>

using namespace nt2;

int main() {
  table<double> x;
  table<double> y = ones(4, 4);

  x = 40.0 * y + 2.0;

  NT2_DISPLAY(x);

  return 0;
}
\end{lstlisting}

\item
\textbf{EVE} \cite{eve} provides generic abstractions over SIMD instructions
as well as SIMD-optimized generic algorithms for the development of
high performance and portable SIMD code \cite{hpcs2018-matvec}.

\begin{lstlisting}[
  language=c++
]{}
#include <eve/module/core.hpp>
#include <eve/wide.hpp>
#include <iostream>

int main() {
  eve::wide<float> x(
      [](auto i, auto) { return 1.f + i; });
  std::cout << "x     = " << x << "\n";
  std::cout << "2*x   = " << x + x << "\n";
  std::cout << "x^0.5 = " << eve::sqrt(x) << "\n";

  return 0;
}
\end{lstlisting}

\item
\textbf{HPX} \cite{hpx} is a \cpp parallel and distributed runtime library.
It can execute small parallel tasks efficiently and distribute
larger distributed tasks with a work following data execution model.
Its parallel and distributed APIs as well as its parallel implementation of
the standard library (based on its own parallel runtime) use metaprogramming
for algorithmic genericity.

\begin{lstlisting}[
  language=c++
]{}
std::uint64_t fibonacci(std::uint64_t n) {
  if (n < 2)
    return n;

  hpx::future<std::uint64_t> n1 =
      hpx::async(fibonacci, n - 1);
  hpx::future<std::uint64_t> n2 =
      hpx::async(fibonacci, n - 2);

  // wait for the futures to return their values
  return n1.get() + n2.get();
}
\end{lstlisting}

\item
\textbf{Thrust} \cite{thrust} implements \acrshort{gpu}-accelerated equivalents
of the Standard Library's algorithms, while CUB \cite{cub} provides
\acrshort{gpu}-optimized algorithm skeletons for generic programming on NVIDIA \gls{gpu}\acrpluralsuffix{}.
AMD and Intel implement their equivalents for their own platforms, respectively
ROCm and OneAPI.

\begin{lstlisting}[
  language=c++
]{}
#include <algorithm>
#include <thrust/device_vector.h>
#include <thrust/functional.h>
#include <thrust/generate.h>
#include <thrust/host_vector.h>
#include <thrust/reduce.h>

int main(void) {
  // generate random data serially
  thrust::host_vector<int> h_vec(100);
  std::generate(h_vec.begin(), h_vec.end(), rand);

  // transfer to device and compute sum
  thrust::device_vector<int> d_vec = h_vec;
  int x = thrust::reduce(d_vec.begin(), d_vec.end(),
                         0, thrust::plus<int>());
  return 0;
}
\end{lstlisting}

\item
\textbf{faer} \cite{faer}

\begin{lstlisting}[
  language=c++
]{}
use faer::{mat, Mat, prelude::*};

// empty 0x0 matrix
let m0: Mat<f64> = Mat::new();

// zeroed 4x3 matrix
let m1: Mat<f64> = Mat::zeros(4, 3);

// 3x3 identity matrix
let m2 = Mat::from_fn(
  3, 3,
  |i, j| if i == j { 1.0 } else { 0.0 });

// 4x2 matrix with custom data
let m3 = mat![
    [4.93, 2.41],
    [5.43, 4.33],
    [9.83, 1.59],
    [7.13, 5.02_f64],
];

// compute the qr decomposition of a matrix
let qr_decomposition = m3.qr();
\end{lstlisting}

\end{itemize}

\end{document}
