\documentclass[../main]{subfiles}
\begin{document}

\section{
  \cpp language constructs for metaprogramming
}

Templates are an interesting technique for generative programming. As they
are Turing-complete \cite{unruh:1994}, one can design a set of
\textbf{template metaprograms} \cite{abrahams:2004} allowing the compiler
to perform arbitrary computation at compile time and generating temporary
\cpp code fragment as an output.
The resulting temporary source code is then
merged with the rest of the source code and finally processed by the classic
compilation process.
\\

Listing \ref{lst:basic-tmp} shows basic principles of \cpp template
metaprogramming. The \lstinline{fibonacci_t} type template accepts an
integer called $N$, and exposes the $N\textsuperscript{th}$ element
of the Fibonacci series as its \lstinline{value} static member.
The template has 3 definitions:
a generic one to calculate elements for $N > 1$,
and two specializations for elements of ranks $0$ and $1$.

\clearpage

\begin{lstlisting}[
  language=C++,
  caption=Example of compile time computation using C++ templates,
  label=lst:basic-tmp
]{}
template <unsigned N> struct fibonacci_t;

template <unsigned N> struct fibonacci_t {
  static constexpr unsigned value =
      fibonacci_t<N - 2>::value + fibonacci_t<N - 1>::value;
};

// Specialization for cases 0 and 1
template <> struct fibonacci_t<0> {
  static constexpr unsigned value = 0;
};

template <> struct fibonacci_t<1> {
  static constexpr unsigned value = 1;
};

std::array<int, fibonacci_t<5>::value> some_array;
\end{lstlisting}

Due to the fact that template code generation is performed at compile time,
it is limited to the use of constants and supports pattern-matching and
recursion thanks to template partial specialization. It can then be looked
at as a pure functional language \cite{haeri:2012}.
The execution of metaprograms by the compiler enables libraries to implement
domain-specific optimizations.
\\

Metaprograms can be seen as programs that take code as input and/or output.
This distinction will be important to explain the work presented in
this thesis, as it focuses a lot on methods to translate
compile time compute results into \cpp programs.

\subsection{
  Different kinds of templates
}

\cpp templates offer ways to output code for data structures, values,
and functions. Ultimately, these kinds outputs constitute what metaprograms
can or cannot generate.

\begin{itemize}

  \item

\textbf{Type templates} to generate data structures.

\begin{lstlisting}[language=c++]{}
template <typename T> struct named_value_t {
  std::string name;
  T value;
};
\end{lstlisting}

  \item

\textbf{Type alias templates} which can be used as abstractions on top of
template types.

\begin{lstlisting}[language=c++]{}
template <typename T>
using nested_named_value_t =
    named_value_t<named_value_t<T>>;
\end{lstlisting}

  \item

\textbf{Function templates} to create generic functions.

\begin{lstlisting}[language=c++]{}
/// Returns a value annotated with
/// its string representation
template <typename T>
named_value_t<T> make_named_value(T value) {
  return named_value_t<T>(std::to_string(value),
                          std::move(value));
}
\end{lstlisting}

  \item

\textbf{Variable templates} to map template parameters to values.

\begin{lstlisting}[language=c++]{}
/// Returns the default value of T annotated with
/// its string representation
template <typename T>
named_value_t<T> annotated_default_v =
    make_named_value(T{});

named_value_t<int> val = annotated_default_v<int>;
\end{lstlisting}

\end{itemize}

\subsection{
  Different kinds of parameters
}

Metaprograms can take many kinds of \cpp constructs as inputs.

\begin{itemize}

  \item

\textbf{Type parameters} are the primary kind of parameter used in \gls{tmp}
in which types are used to represent everything from enumerations, arrays,
or even functions.

  \item

\textbf{\glspl{nttp}} are complementary with type parameters.
They can be used to wrap values within types, which can be particularly useful
in the context of \gls{tmp}. For example a type template definition like
\lstinline|template<int I> integer_t{};| allows integers to be stored as types.

  \item

\textbf{Parameter packs} make it possible for templates to have an
arbitrary number of parameters, as long as types and values
are not mixed together. Parameter packs also exist for function parameters,
which can be useful for template parameter deduction.

For example a type template definition like
\lstinline|template<typename ... Ts> tuple_t{};| can be used to store an
arbitrary list of types as a single type.

  \item

\textbf{\gls{constexpr} function parameters}, even though not all of them can be
used as \glspl{nttp}, they can be used to produce \gls{nttp} compatible values.

\end{itemize}

\subsection{
  Advanced \cpp template mechanisms
}

\begin{itemize}
  \item

\textbf{Template specialization} allows specializing a template for a given
set of type or value parameters. A template that has a single boolean parameter
can, for example, expose two different implementations depending on the
parameter's value.

  \item

\textbf{Template parameter deduction} works as a form of pattern matching
for function template parameters, types and values alike. It can filter
parameter patterns, and deduce nested template parameters in those patterns.

  \item

\textbf{\gls{sfinae}} is a \cpp principle that consists in not triggering a
compilation error when a type substitution cannot be done in a template
instantiation. Instead the type, function, or variable will simply be disabled
and the next candidate will be instantiated.

  \item

\textbf{Parameter pack expansion} allows mapping operations and performing
reductions on parameter packs.

\end{itemize}

\subsection{
  Compile time logic
}

Compile time logic can be achieved in many \cpp constructs.

\begin{itemize}

  \item

\textbf{Computation using types}, also known as type-based metaprogramming.
Types can be used to represent scalar values, arrays, and many more
kinds of data structures including expression trees. They can also

  \item

\textbf{Computation using values} thanks to \glspl{nttp}.
They allow a slightly more explicit way to write metaprograms,
as values are represented by values instead of types.
Not all values are accepted as \gls{nttp}.
Until \cpp20, only integral values (\ie integers, booleans, etc.)
could be used as \gls{nttp}.

  \item

\textbf{Computation using \gls{constexpr} functions} since \cpp11,
although only a limited subset of \cpp can run in \glspl{consteval}.
Memory allocations have been allowed in this context only since \cpp20.

\end{itemize}

The use of \gls{constexpr} functions for compile time programming might be
preferable for many reasons: they are familiar to all \cpp developers
(and, as such, are more maintainable), they allow the use of types to enforce
semantics properly as opposed to type-based metaprogramming, and they allow
compile time programs to run much faster than pure \gls{tmp} does.

\section{
  Metaprogramming libraries
}
\label{lbl:meta-libraries}

As previously said \cpp templates can be seen as a functional language.
Over time a range of libraries emerged, aiming to provide functionalities
similar to regular language such as containers and algorithms for use in
template metaprograms. Notable examples of such libraries are MPL\cite{mpl},
Brigand\cite{brigand}, and mp11 \cite{mp11}.

\begin{lstlisting}[
  language=c++,
  caption=boost.mp11 code example,
  label=lst:mp11-example
]{}
template <int X> struct equals_to {
  template <typename Y>
  using apply = mp_bool<X == Y::type::value>;
};

using my_list = mp_list_c<int, 0, 2, 4, 6, 8, 10>;

using pos_of_6 =
    mp_find_if<my_list, equals_to<6>::apply>; // 3
\end{lstlisting}

\begin{lstlisting}[
  language=c++,
  caption=Brigand code example,
  label=lst:brigand-example
]{}
using my_list =
    brigand::integral_list<int, 0, 2, 4, 6, 8, 10>;

using pos_of_6 = brigand::size<brigand::find<
    my_list, std::is_same<brigand::_1,
                          brigand::integral_constant<
                              int, 6>>>>; // 3
\end{lstlisting}

Listings \ref{lst:mp11-example} and \ref{lst:brigand-example} show
how to use mp11 and Brigand to perform a basic task: finding the index of a
value in a list at compile time.
\\

Libraries for more specific uses were also introduced, such as
\gls{ctre} \cite{ctre} for compiling regular expressions,
and \gls{ctpg} \cite{ctpg} for generating LR1 parsers
(also not for compile time parsing).

\begin{lstlisting}[
  language=c++,
  caption=\gls{ctre} code example
]{}
auto input = "123,456,768"sv;

for (auto match : ctre::range<"([0-9]+),?">(input)) {
  std::cout << std::string_view{match.get<0>()}
            << "\n";
}
\end{lstlisting}

All these libraries either enable \gls{tmp}, or use \gls{tmp} to achieve
a specific goal. However with the introduction of \gls{constexpr} programming,
a new range of compile time libraries aim to provide new capabilities
for this new metaprogramming paradigm.

The C'est\cite{cest} is one such example, as it aims to be a \gls{constexpr}
compatible replacement for the \cpp standard library. It implements the same
containers and algorithms, although all of them usable in \glspl{consteval}.
For example, \lstinline{std::deque} is not usable in \glspl{consteval} whereas
its C'est equivalent (\lstinline{cest::deque}) is.

\begin{lstlisting}[
  language=c++,
  caption=C'est code example,
  label=lst:cest-example
]{}
constexpr std::size_t
find_pos(int element,
         cest::vector<int> const &elements) {
  return cest::find(elements.begin(), elements.end(),
                    element) -
         elements.end();
}

constexpr std::size_t pos_of_6 =
    find_pos(6, {0, 2, 4, 6, 8, 10});
\end{lstlisting}

In listing \ref{lst:cest-example} we can see an example compile time program
equivalent to what was shown for Brigand and mp11. Thanks to new \cpp features,
metaprogramming can be partially done using \cpp code. This makes
compile time programs significantly easier to write and understand.

All these examples show that metaprogramming is not just a gimmick.
There is enough interest in leveraging metaprogramming
for generic programming that many frameworks, libraries, or languages
have been developed around this paradigm and maintained sometimes
for more than a decade. Its adoption in languages like Braid, Julia, Terra,
Rust, or Dlang shows that it is not limited to \cpp.

However, most of generic libraries and frameworks that are developed
and maintained today are based on \cpp, and \cpp itself is likely to
evolve to provide more ways to generate programs as shown by the recent
standard proposal for Scalable Reflection in \cpp \cite{scalable-reflection}.

\section{
  Applications of metaprogramming for HPC
}

Metaprogramming can bring significant benefits to libraries:

\begin{itemize}

  \item

\textbf{Performance}: notably in the case of \gls{ctre}.
Regular expressions are usually interpreted at runtime,
which adds a measurable overhead to text processing.
\gls{ctre} shows leading performance, on par with Rust's regex library
which also works by compiling regular expressions.

  \item

\textbf{Language integration}: since these are \cpp libraries,
their APIs can take advantage of \cpp operator overloading and lambdas.
In \gls{ctpg}, these are used to provide a domain-specific language that is close to
what parser generators like YACC or Bison provide,
though it is still regular \cpp code which can be put inside any function body.
Using a \cpp API makes these libraries easier to learn
as the syntax is already familiar to their users.

  \item

\textbf{Streamlined toolchain}: as they only require to be included as headers.
This avoids complicating compilation toolchains by requiring additional programs
to be installed and integrated to the build system.

\end{itemize}

These qualities make metaprogramming a good candidate for the implementation
of comprehensive \gls{hpc} toolkits that would otherwise have
slower implementations, or otherwise rely on compiler extensions like OpenMP.

As such, there are many \cpp \gls{hpc} libraries that use metaprogramming
more or less extensively:

\begin{itemize}

  \item

\textbf{Eigen} \cite{eigen} is the first major \cpp library to implement
Expression templates for the generation of high performance math computing.
Expression templates is a \cpp design pattern that consists in representing
math expressions with type template trees. We will discuss them later
in \ref{lbl:expression-level-metaprogramming}.

\begin{lstlisting}[
  language=c++
]{}
#include <Eigen/Dense>
#include <iostream>

using Eigen::MatrixXd;
using Eigen::VectorXd;

int main() {
  MatrixXd m = MatrixXd::Random(3, 3);
  m = (m + MatrixXd::Constant(3, 3, 1.2)) * 50;
  std::cout << "m =" << std::endl << m << std::endl;
  VectorXd v(3);
  v << 1, 2, 3;
  std::cout << "m * v =" << std::endl
            << m * v << std::endl;
}
\end{lstlisting}

  \item

\textbf{Blaze} \cite{blazelib} is a successor of Eigen that implements so-called
"Smart Expression Templates" which extends upon the concept of
expression templates implemented by Eigen. It aims to provide a more performant
and extensible \gls{hpc} library. However, Eigen is not set in stone
and its designed has since been updated.

\begin{lstlisting}[
  language=c++
]{}
#include <blaze/Math.h>
#include <iostream>

using blaze::DynamicVector;
using blaze::StaticVector;

int main() {
  StaticVector<int, 3UL> a{4, -2, 5};
  DynamicVector<int> b(3UL);

  b[0] = 2;
  b[1] = 5;
  b[2] = -3;

  DynamicVector<int> c = a + b;

  std::cout << "c =\n" << c << "\n";
}
\end{lstlisting}

  \item

\textbf{NT2} \cite{nt2} is a research project that aims to provide a complete
numerical toolbox that leverages metaprogramming to develop portable \gls{hpc}
applications with a Matlab-like interface while still achieving state-of-the-art
computing performance.

\begin{lstlisting}[
  language=c++
]{}
#include <nt2/include/functions/ones.hpp>
#include <nt2/table.hpp>

using namespace nt2;

int main() {
  table<double> x;
  table<double> y = ones(4, 4);

  x = 40.0 * y + 2.0;

  NT2_DISPLAY(x);

  return 0;
}
\end{lstlisting}

  \item

\textbf{EVE} \cite{eve} provides generic abstractions over SIMD instructions
as well as SIMD-optimized generic algorithms for the development of
high performance and portable SIMD code \cite{hpcs2018-matvec}.

\begin{lstlisting}[
  language=c++
]{}
#include <eve/module/core.hpp>
#include <eve/wide.hpp>
#include <iostream>

int main() {
  eve::wide<float> x(
      [](auto i, auto) { return 1.f + i; });
  std::cout << "x     = " << x << "\n";
  std::cout << "2*x   = " << x + x << "\n";
  std::cout << "x^0.5 = " << eve::sqrt(x) << "\n";

  return 0;
}
\end{lstlisting}

  \item

\textbf{HPX} \cite{hpx} is a \cpp parallel and distributed runtime library.
It can execute small parallel tasks efficiently and distribute
larger distributed tasks with a work following data execution model.
Its parallel and distributed APIs as well as its parallel implementation of
the standard library (based on its own parallel runtime) use metaprogramming
for algorithmic genericity.

\begin{lstlisting}[
  language=c++
]{}
std::uint64_t fibonacci(std::uint64_t n) {
  if (n < 2)
    return n;

  hpx::future<std::uint64_t> n1 =
      hpx::async(fibonacci, n - 1);
  hpx::future<std::uint64_t> n2 =
      hpx::async(fibonacci, n - 2);

  // wait for the futures to return their values
  return n1.get() + n2.get();
}
\end{lstlisting}

  \item

\textbf{Thrust} \cite{thrust} implements \gls{gpu}-accelerated equivalents
of the Standard Library's algorithms, while CUB \cite{cub} provides
\gls{gpu}-optimized algorithm skeletons for generic programming on NVIDIA
\glspl{gpu}.
AMD and Intel implement their equivalents for their own platforms, respectively
ROCm and OneAPI.

\begin{lstlisting}[
  language=c++
]{}
#include <algorithm>
#include <thrust/device_vector.h>
#include <thrust/functional.h>
#include <thrust/generate.h>
#include <thrust/host_vector.h>
#include <thrust/reduce.h>

int main(void) {
  // generate random data serially
  thrust::host_vector<int> h_vec(100);
  std::generate(h_vec.begin(), h_vec.end(), rand);

  // transfer to device and compute sum
  thrust::device_vector<int> d_vec = h_vec;
  int x = thrust::reduce(d_vec.begin(), d_vec.end(),
                         0, thrust::plus<int>());
  return 0;
}
\end{lstlisting}

\end{itemize}

These libraries operate at many different levels: some of them provide
high level declarative APIs for math computing, while others provide generic
building blocks to write generic compute kernels.

In the next chapter, I will focus on the use of Boost.SIMD \cite{bsimd}
for the generation of BLAS-compatible linear algebra kernels.

\end{document}
