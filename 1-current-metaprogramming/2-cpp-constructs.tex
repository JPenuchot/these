\documentclass[../main]{subfiles}
\begin{document}

\section{
  \cpp language constructs for metaprogramming
}

Templates are an interesting feature for metaprogramming. As they
are Turing-complete \cite{unruh:1994}, one can design a set of
\textbf{template metaprograms} \cite{abrahams:2004} allowing the compiler
to perform arbitrary computation at compile time and generating temporary
\cpp code fragment as an output.
The resulting temporary source code is then
merged with the rest of the source code and finally processed by the classic
compilation process.
\\

Listing \ref{lst:basic-tmp} shows basic principles of \cpp template
metaprogramming. The \lstinline{fibonacci_t} type template accepts an
integer called $N$, and exposes the $N\textsuperscript{th}$ element
of the Fibonacci series as its \lstinline{value} static member.
The template has 3 definitions:
a generic one to calculate elements for $N > 1$,
and two specializations for elements of ranks $0$ and $1$.

\begin{lstlisting}[
  language=C++,
  caption=Example of compile time computation using C++ templates,
  label=lst:basic-tmp
]{}
template <unsigned N> struct fibonacci_t;

template <unsigned N> struct fibonacci_t {
  static constexpr unsigned value =
      fibonacci_t<N - 2>::value + fibonacci_t<N - 1>::value;
};

// Specialization for cases 0 and 1
template <> struct fibonacci_t<0> {
  static constexpr unsigned value = 0;
};

template <> struct fibonacci_t<1> {
  static constexpr unsigned value = 1;
};

std::array<int, fibonacci_t<5>::value> some_array;
\end{lstlisting}

Due to the fact that template code generation is performed at compile time,
it is limited to the use of constants and supports pattern-matching and
recursion thanks to template partial specialization. It can then be looked
at as a pure functional language \cite{haeri:2012}.
The execution of metaprograms by the compiler enables libraries to implement
domain-specific optimizations.
\\

Metaprograms can be seen as programs that take code as input and/or output.
This distinction will be important to explain the work presented in
this thesis, as it focuses a lot on methods to translate
compile time compute results into \cpp programs.

\subsection{
  Different kinds of templates
}

\cpp templates offer ways to output code for data structures, values,
and functions. Ultimately, these kinds outputs constitute what metaprograms
can or cannot generate.

\begin{itemize}

  \item

\textbf{Type templates} to generate data structures.

\begin{lstlisting}[language=c++]{}
template <typename T> struct named_value_t {
  std::string name;
  T value;
};
\end{lstlisting}

  \item

\textbf{Type alias templates} which can be used as abstractions on top of
template types.

\begin{lstlisting}[language=c++]{}
template <typename T>
using nested_named_value_t =
    named_value_t<named_value_t<T>>;
\end{lstlisting}

  \item

\textbf{Function templates} to create generic functions.

\begin{lstlisting}[language=c++]{}
/// Returns a value annotated with
/// its string representation
template <typename T>
named_value_t<T> make_named_value(T value) {
  return named_value_t<T>(std::to_string(value),
                          std::move(value));
}
\end{lstlisting}

  \item

\textbf{Variable templates} to map template parameters to values.

\begin{lstlisting}[language=c++]{}
/// Returns the default value of T annotated with
/// its string representation
template <typename T>
named_value_t<T> annotated_default_v =
    make_named_value(T{});

named_value_t<int> val = annotated_default_v<int>;
\end{lstlisting}

\end{itemize}

\subsection{
  Different kinds of parameters
}

Metaprograms can take many kinds of \cpp constructs as inputs.

\begin{itemize}

  \item

\textbf{Type parameters} are the primary kind of parameter used in \gls{tmp}
in which types are used to represent everything from enumerations, arrays,
or even functions.

  \item

\textbf{\glspl{nttp}} are complementary with type parameters.
They can be used to wrap values within types, which can be particularly useful
in the context of \gls{tmp}. For example a type template definition like
\lstinline|template<int I> integer_t{};| allows integers to be stored as types.

  \item

\textbf{Parameter packs} make it possible for templates to have an
arbitrary number of parameters, as long as types and values
are not mixed together. Parameter packs also exist for function parameters,
which can be useful for template parameter deduction.

For example a type template definition like
\lstinline|template<typename ... Ts> tuple_t{};| can be used to store an
arbitrary list of types as a single type.

  \item

\textbf{\gls{constexpr} function parameters}, even though not all of them can be
used as \glspl{nttp}, they can be used to produce \gls{nttp} compatible values.

\end{itemize}

\subsection{
  Advanced \cpp template mechanisms
}

\begin{itemize}
  \item

\textbf{Template specialization} allows specializing a template for a given
set of type or value parameters. A template that has a single boolean parameter
can, for example, expose two different implementations depending on the
parameter's value.

  \item

\textbf{Template parameter deduction} works as a form of pattern matching
for function template parameters, types and values alike. It can filter
parameter patterns, and deduce nested template parameters in those patterns.

  \item

\textbf{\gls{sfinae}} is a \cpp principle that consists in not triggering a
compilation error when a type substitution cannot be done in a template
instantiation. Instead the type, function, or variable will simply be disabled
and the next candidate will be instantiated.

  \item

\textbf{Parameter pack expansion} allows mapping operations and performing
reductions on parameter packs.

\end{itemize}

\subsection{
  Compile time logic
}

Compile time logic can be achieved in many \cpp constructs.

\begin{itemize}

  \item

\textbf{Computation using types}, also known as type-based metaprogramming.
Types can be used to represent scalar values, arrays, and many more
kinds of data structures including expression trees. They can also

  \item

\textbf{Computation using values} thanks to \glspl{nttp}.
They allow a slightly more explicit way to write metaprograms,
as values are represented by values instead of types.
Not all values are accepted as \gls{nttp}.
Until \cpp20, only integral values (\ie integers, booleans, etc.)
could be used as \gls{nttp}.

  \item

\textbf{Computation using \gls{constexpr} functions} since \cpp11,
although only a limited subset of \cpp can run in \glspl{consteval}.
Memory allocations have been allowed in this context only since \cpp20.

\end{itemize}

The use of \gls{constexpr} functions for compile time programming might be
preferable for many reasons: they are familiar to all \cpp developers
(and, as such, are more maintainable), they allow the use of types to enforce
semantics properly as opposed to type-based metaprogramming, and they allow
compile time programs to run much faster than pure \gls{tmp} does.

% TODO: Faire la liaison pour integrer (voir HDR de Joel)
\section{
  Domain specific embedded language
}
\label{lbl:expression-level-metaprogramming}

% TODO: Citer un peu boost.proto

% DEBUT
\glspl{dsel} in \cpp use \gls{tmp} via the \textit{Expression Template} idiom.
\textbf{Expression Templates} \cite{veldhuizen:1995,vandevoorde:2002} is a
technique implementing a form of \textbf{delayed evaluation} in
\cpp \cite{spinellis:2001}. Expression Templates are built around the
\textit{recursive type composition} idiom \cite{jarvi:1998} that allows the
construction, at compile time, of a type representing the \gls{ast}
of an arbitrary statement. This is done by overloading functions and operators
on those types so they return a lightweight object.
The object encodes the current operation in the \gls{ast}
being built in its type instead of performing any kind of computation.
Once reconstructed, this \gls{ast} can be transformed into arbitrary code fragments
using Template Metaprograms.

As of today, most \cpp EDSLs rely on \textit{Expression Templates} and therefore
are limited to the \cpp syntax. New techniques are becoming more popular through
the use of \gls{constexpr} strings to embed arbitray
\glspl{dsel}. One major example is the \gls{ctre} \cite{ctre}
that implements most of the \gls{pcre} syntax.
However, \gls{ctre} still relies on type-based \gls{tmp} to parse
regular expressions and transform them into regular expression evaluators.
% FIN

In this chapter I will cover the use of \gls{tmp} for higher levels
of abstraction. Templates can be used to represent whole mathematical
expressions at compile time by creating type-based arborescences.
This type of representation is called an \gls{et} \cite{veldhuizen:1995}.

Combined with compile-time mechanisms such as function overloading,
specialization, and operator overloading, \gls{et}\acrpluralsuffix{} can be used to
implement expression level \gls{dsel}\acrpluralsuffix{} and convert complex
mathematical expressions into high performance code.

There are two main libraries that are able to do just this: Eigen \cite{eigen}
and Blaze \cite{blazelib}, which were cited in \ref{lbl:meta-libraries}.
In this section, I will introduce the basics of \cpp \gls{tmp},

\subsection{
  Expression templates: a type-based representation of math formulas
}

Expression templates are template trees that represent math formulas.
They are generated using operator and function overloading from expressions
that must be known at compile time.

\begin{figure}[h]
\includegraphics[width=\textwidth]{images/expressiontemplates.pdf}
\caption{
  Expression template evaluation illustration,
  taken from Joel Falcou's HDR thesis \cite{falcou-hdr}
}
\label{fig:expression-template-illustration}
\end{figure}

Figure \ref{fig:expression-template-illustration} shows the basic
working principle of \glspl{et}: an operation involving matrices generates
a type hirarchy that represents the operation itself, and the assignment
of this expression to \lstinline{x} triggers the generation of
an optimized program that computes the operation.

They enable a whole range of optimizations:

\begin{itemize}
\item
\textbf{Lazy evaluation} is easily implemented through the generation
of single element access operators that calculate single element values.

\item
\textbf{\gls{blas} functions} can be used on complex operations that
benefit from highly optimized implementations. For example while
element-wise operations such as vector additions might better use
lazy evaluation, more complex operations such as matrix-matrix multiplications
require more hardware-specific tuning.

\item
\textbf{Multi-threading} can be implemented via parallel assignment functions.

\item
\textbf{\gls{simd} optimizations} can be implemented through vector access
operators to combine the benefits of lazy evaluation and \gls{simd} computing.
\end{itemize}

\subsubsection{
  \acrlong{gpu} support efforts
}

Lots of rewrite to do

Potentially a job for source rewriting tools

\begin{itemize}
\item Eventually: \gls{gpu} code generation, although Blaze needs a significant
      rewrite for that. Source rewriting tools might be a good fit for that job.
\end{itemize}

Expression templates can provide expression level APIs for \gls{hpc} libraries.

Still two limitations:

\begin{itemize}
\item Slow compilation times
\item \cpp syntax only
\end{itemize}

Expression templates are aging (pretty well but still).
Newer \cpp standards provide metaprogramming features that can fundamentally
change the way we write metaprograms.

The next part of my thesis will focus on how to leverage these features to
implement \gls{dsel} of arbitrary syntax, and the study of their impact on
compilation times.


\section{
  Metaprogramming libraries
}
\label{lbl:meta-libraries}

\subsection{
  Type based metaprogramming
}

% TODO: Pour les exemples de code,
% mettre les explications avant les bouts de code
% et etoffer les explications pour donner plus de details

As previously said \cpp templates can be seen as a functional language.
Over time a range of libraries emerged, aiming to provide functionalities
similar to regular language such as containers and algorithms for use in
template metaprograms. Notable examples of such libraries are MPL\cite{mpl},
Brigand\cite{brigand}, and mp11 \cite{mp11}.

\begin{lstlisting}[
  language=c++,
  caption=boost.mp11 code example,
  label=lst:mp11-example
]{}
/// A predicate is implemented as a structure template
template <int X> struct equals_to {
  template <typename Y>
  using apply = mp_bool<X == Y::type::value>;
};

/// We store a number list as a type alias called `my`
using my_list = mp_list_c<int, 0, 2, 4, 6, 8, 10>;

using pos_of_6 =
    mp_find_if<my_list, equals_to<6>::apply>; // 3
\end{lstlisting}

\begin{lstlisting}[
  language=c++,
  caption=Brigand code example,
  label=lst:brigand-example
]{}
using my_list =
    brigand::integral_list<int, 0, 2, 4, 6, 8, 10>;

using pos_of_6 = brigand::size<brigand::find<
    my_list, std::is_same<brigand::_1,
                          brigand::integral_constant<
                              int, 6>>>>; // 3
\end{lstlisting}

Listings \ref{lst:mp11-example} and \ref{lst:brigand-example} show
how to use mp11 and Brigand to perform a basic task: finding the index of a
value in a list at compile time.

All these libraries either enable \gls{tmp}, or use \gls{tmp} to achieve
a specific goal. However with the introduction of \gls{constexpr} programming,
a new range of compile time libraries aim to provide new capabilities
for this new metaprogramming paradigm.

\subsection{
  Value based metaprogramming
}

The C'est\cite{cest} is one such example, as it aims to be a \gls{constexpr}
compatible replacement for the \cpp standard library. The development was
started by Paul Keir, and I contributed by implementing
\lstinline{cest::unique_ptr} which was needed to implement the Brainfuck parser
in \ref{lbl:ptr-tree-codegen} before \lstinline{std::unique_ptr} became
\gls{constexpr} compatible in libstdc++.

It implements the same containers and algorithms as the \cpp standard library,
although all of them usable in \glspl{consteval}. For example,
\lstinline{std::deque} is not usable in \glspl{consteval} whereas
its C'est equivalent (\lstinline{cest::deque}) is.

\begin{lstlisting}[
  language=c++,
  caption=C'est code example,
  label=lst:cest-example
]{}
constexpr std::size_t
find_pos(int element,
         cest::vector<int> const &elements) {
  return cest::find(elements.begin(), elements.end(),
                    element) -
         elements.end();
}

constexpr std::size_t pos_of_6 =
    find_pos(6, {0, 2, 4, 6, 8, 10});
\end{lstlisting}

\subsection{
  Domain specific metaprogramming
}

Libraries for more specific uses were also introduced, such as
\gls{ctre} \cite{ctre} for compiling regular expressions,
and \gls{ctpg} \cite{ctpg} for generating LR1 parsers
(also not for compile time parsing).

\begin{lstlisting}[
  language=c++,
  caption=\gls{ctre} code example
]{}
auto input = "123,456,768"sv;

for (auto match : ctre::range<"([0-9]+),?">(input)) {
  std::cout << std::string_view{match.get<0>()}
            << "\n";
}
\end{lstlisting}

In listing \ref{lst:cest-example} we can see an example compile time program
equivalent to what was shown for Brigand and mp11. Thanks to new \cpp features,
metaprogramming can be partially done using \cpp code. This makes
compile time programs significantly easier to write and understand.

However, most of generic libraries and frameworks that are developed
and maintained today are based on \cpp, and \cpp itself is likely to
evolve to provide more ways to generate programs as shown by the recent
standard proposal for Scalable Reflection in \cpp \cite{scalable-reflection}.

\section{
  Applications of metaprogramming for HPC
}

Metaprogramming can bring significant benefits to libraries:

\begin{itemize}

  \item

\textbf{Performance}: notably in the case of \gls{ctre}.
Regular expressions are usually interpreted at runtime,
which adds a measurable overhead to text processing.
\gls{ctre} shows leading performance, on par with Rust's regex library
which also works by compiling regular expressions.

  \item

\textbf{Language integration}: since these are \cpp libraries,
their APIs can take advantage of \cpp operator overloading and lambdas.
In \gls{ctpg}, these are used to provide a domain-specific language that is close to
what parser generators like YACC or Bison provide,
though it is still regular \cpp code which can be put inside any function body.
Using a \cpp API makes these libraries easier to learn
as the syntax is already familiar to their users.

  \item

\textbf{Streamlined toolchain}: as they only require to be included as headers.
This avoids complicating compilation toolchains by requiring additional programs
to be installed and integrated to the build system.

\end{itemize}

These qualities make metaprogramming a good candidate for the implementation
of comprehensive \gls{hpc} toolkits that would otherwise have
slower implementations, or otherwise rely on compiler extensions like OpenMP.

As such, there are many \cpp \gls{hpc} libraries that use metaprogramming
more or less extensively:

\begin{itemize}

  \item

\textbf{Eigen} \cite{eigen} is the first major \cpp library to implement
Expression templates for the generation of high performance math computing.
Expression templates is a \cpp design pattern that consists in representing
math expressions with type template trees. We will discuss them later
in \ref{lbl:expression-level-metaprogramming}.

\begin{lstlisting}[
  language=c++
]{}
using Eigen::MatrixXd;
using Eigen::VectorXd;

int main() {
  MatrixXd m = MatrixXd::Random(3, 3);
  m = (m + MatrixXd::Constant(3, 3, 1.2)) * 50;
  std::cout << "m =" << std::endl << m << std::endl;
  VectorXd v(3);
  v << 1, 2, 3;
  std::cout << "m * v =" << std::endl
            << m * v << std::endl;
}
\end{lstlisting}

  \item

\textbf{Blaze} \cite{blazelib} is a successor of Eigen that implements so-called
"Smart Expression Templates" which extends upon the concept of
expression templates implemented by Eigen. It aims to provide a more performant
and extensible \gls{hpc} library. However, Eigen is not set in stone
and its designed has since been updated.

\begin{lstlisting}[
  language=c++
]{}
using blaze::DynamicVector;
using blaze::StaticVector;

int main() {
  StaticVector<int, 3UL> a{4, -2, 5};
  DynamicVector<int> b(3UL);

  b[0] = 2;
  b[1] = 5;
  b[2] = -3;

  DynamicVector<int> c = a + b;

  std::cout << "c =\n" << c << "\n";
}
\end{lstlisting}

  \item

\textbf{NT2} \cite{nt2} is a research project that aims to provide a complete
numerical toolbox that leverages metaprogramming to develop portable \gls{hpc}
applications with a Matlab-like interface while still achieving state-of-the-art
computing performance.

\begin{lstlisting}[
  language=c++
]{}
using namespace nt2;

int main() {
  table<double> x;
  table<double> y = ones(4, 4);

  x = 40.0 * y + 2.0;

  NT2_DISPLAY(x);
}
\end{lstlisting}

  \item

\textbf{EVE} \cite{eve} provides generic abstractions over SIMD instructions
as well as SIMD-optimized generic algorithms for the development of
high performance and portable SIMD code \cite{hpcs2018-matvec}.

\begin{lstlisting}[
  language=c++
]{}
int main() {
  eve::wide<float> x(
      [](auto i, auto) { return 1.f + i; });
  std::cout << "x     = " << x << "\n";
  std::cout << "2*x   = " << x + x << "\n";
  std::cout << "x^0.5 = " << eve::sqrt(x) << "\n";
}
\end{lstlisting}

  \item

\textbf{HPX} \cite{hpx} is a \cpp parallel and distributed runtime library.
It can execute small parallel tasks efficiently and distribute
larger distributed tasks with a work following data execution model.
Its parallel and distributed APIs as well as its parallel implementation of
the standard library (based on its own parallel runtime) use metaprogramming
for algorithmic genericity.

\begin{lstlisting}[
  language=c++
]{}
std::uint64_t fibonacci(std::uint64_t n) {
  if (n < 2)
    return n;

  hpx::future<std::uint64_t> n1 =
      hpx::async(fibonacci, n - 1);
  hpx::future<std::uint64_t> n2 =
      hpx::async(fibonacci, n - 2);

  // wait for the futures to return their values
  return n1.get() + n2.get();
}
\end{lstlisting}

  \item

\textbf{Thrust} \cite{thrust} implements \gls{gpu}-accelerated equivalents
of the Standard Library's algorithms, while CUB \cite{cub} provides
\gls{gpu}-optimized algorithm skeletons for generic programming on NVIDIA
\glspl{gpu}.
AMD and Intel implement their equivalents for their own platforms, respectively
ROCm and OneAPI.

\begin{lstlisting}[
  language=c++
]{}
int foo() {
  // generate random data serially
  thrust::host_vector<int> h_vec(100);
  std::generate(h_vec.begin(), h_vec.end(), rand);

  // transfer to device and compute sum
  thrust::device_vector<int> d_vec = h_vec;
  return thrust::reduce(d_vec.begin(), d_vec.end(), 0,
                        thrust::plus<int>());
}
\end{lstlisting}

\end{itemize}

These libraries operate at many different levels: some of them provide
high level declarative APIs for math computing, while others provide generic
building blocks to write generic compute kernels.

\section{
  Conclusion
}

% TODO: Refondre ce paragraphe pour mieux resumer le chapitre
All these examples show that metaprogramming is not just a gimmick.
There is enough interest in leveraging metaprogramming
for generic programming that many frameworks, libraries, or languages
have been developed around this paradigm and maintained sometimes
for more than a decade. Its adoption in languages like Braid, Julia, Terra,
Rust, or Dlang shows that it is not limited to \cpp.

In the next chapter, I will focus on the use of Boost.SIMD \cite{bsimd}
for the generation of \gls{blas}-compatible linear algebra kernels.

\end{document}
