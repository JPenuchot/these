\documentclass[../main]{subfiles}
\begin{document}

\section{
  Metaprogramming styles and languages
}

Metaprogramming is not an new concept. It perpetuates itself in contemporary
languages, with some being more widespread than others.

I will focus on partial specialization, which consists in separating
static parts of programs from the dynamic parts in order to interpret
the static parts at compile time and leave only the dynamic parts for the
program's execution \cite{10.1145/243439.243447, 10.1023/A:1010095604496}.
When the target architecture is known during the compilation, partial evaluation
can be leveraged to optimize critical parts of high performance applications
by specializing (or tuning) these parts for it.

In \cpp, templates serve as an interface for partial specialization.
However, many other ways to implement it exist across a wide range of languages
spanning more than half a century.

\begin{itemize}

% TODO: Rajouter les dates de visite pour les liens en footnotes

\item
\textbf{The C and C++ preprocessor} acts as rudimentary token manipulation stage
that was not originally made for metaprogramming, but it can be used
to emulate complex logic, such as functional languages. As such, it can even
be used for high performance code generation \cite{6662183}.

In listing \ref{lst:c-preproc-example} we can see the Boost.Preprocessor library
being used to emulate a tuple structure to select a variable qualifier depending
on an arbitrary number.

\begin{lstlisting}[
  language={c++},
  caption={C++ macro usage example \protect\footnotemark{}},
  label={lst:c-preproc-example}
]{}
#include <boost/preprocessor/facilities/apply.hpp>
#include <boost/preprocessor/tuple/elem.hpp>

#define CV(i)                                    \
  BOOST_PP_APPLY(BOOST_PP_TUPLE_ELEM(            \
      4, i,                                      \
      (BOOST_PP_NIL, (const), (volatile),        \
       (const volatile))))

CV(0) // expands to nothing
CV(1) // expands to const
\end{lstlisting}
\footnotetext{\url{https://www.boost.org/doc/libs/1_85_0/libs/preprocessor/doc/ref/apply.html}}

\item
% TODO: rajouter une ref
\textbf{Lisp macros}
are known for being one of the oldest, yet one of the most powerful
examples among all metaprogramming paradigms. The List macros, as opposed to
C and \cpp macros, can make complete use of the Lisp language itself
with powerful reflection capabilities.
Anecdotally, common imperative language constructs such as the while loop
can be implemented using macros as shown in listing \ref{lst:lisp-while}.

\begin{lstlisting}[
  language={lisp},
  caption={Definition of the \lstinline{while} Lisp macro\protect\footnotemark{}},
  label=lst:lisp-while
]{}
(defmacro while (condition &body body)
  `(loop while ,condition do (progn ,@body)))
\end{lstlisting}
\footnotetext{\url{https://lisp-lang.org/learn/macros}}

\item
\textbf{MetaOCaml} \cite{metaocaml} implements quoting and splicing
\ie the ability to essentially copy and paste expressions,
as well as staged compilation to evaluate statements at compile-time.
This enables code generation to occur both at runtime and at compile-time,
and extends OCaml's partial evaluation capabilities.

Listing \ref{lst:metaocaml-spower} shows an example of runtime specialization
of a power function called \lstinline{spowern}. It takes an integer $N$
as an input, and returns a function that calculates the $N^{th}$ power
of its single input parameter.

\begin{lstlisting}[
  language=caml,
  caption={Run-time specialization of the power function in MetaOCaml\protect\footnotemark{}},
  label={lst:metaocaml-spower}
]{}
let rec spower : int -> int code -> int code =
  fun n x ->
    if n = 0 then .<1>.
    else if n mod 2 = 0
      then .< square .~(spower (n/2) x) >.
      else .<.~x * .~(spower (n-1) x)>.

let spowern : int -> (int -> int) code =
   fun n -> .<fun x -> .~(spower n .<x>.)>.;;
\end{lstlisting}
\footnotetext{\url{https://okmij.org/ftp/meta-programming/tutorial/}}

\item
\textbf{DLang} more or less extends the \cpp Metaprogramming model.
It leverages templates and compile time function evaluation just like
its predecessor.

Compile-time evaluation is much more permissive and mixins enable to generate
code in a more direct way than \cpp. Dlang mixins allow injecting code in
functions and structures in two ways: using template mixins
which are pre-parsed constructs that can be injected later,
as well as string mixins that allow strings containing Dlang code
to be compiled and inserted directly into programs.

Other metaprogramming constructs exists in Dlang, such as \lstinline{static if}
shown in listing \ref{lst:dlang-static-if}, which is an equivalent of
\lstinline{if constexpr} in \cpp.

\begin{lstlisting}[
  language=dlang,
  caption={Use of \lstinline{static if} in Dlang\protect\footnotemark{}},
  label={lst:dlang-static-if}
]{}
static if(is(T == int))
    writeln("T is an int");
static if (is(typeof(x) :  int))
    writeln("x implicitly converts to int");
\end{lstlisting}
\footnotetext{\url{https://tour.dlang.org/tour/en/gems/template-meta-programming}}

\item
\textbf{Rust} proposes metaprogramming through macros, generics, and traits.
In a similar way to Lisp macros, Rust macros can use the host language
as a whole. Additionally, bits of code can explicitely be parsed and reflected
upon at compile time.

Here we can find an example taken from The Rust Programming Language
book \cite{rust-book} where a simplified version of the \lstinline{vec!} macro,
which initializes a vector and pre-fills it with a static number of values,
is defined:

Listing \ref{lst:rust-vec-macro} shows how the \lstinline{vec!} standard macro
can be defined. Note that the Rust standard library preallocates

\begin{lstlisting}[
  language=rust,
  caption={Definition of the \lstinline{vec!} macro\protect\footnotemark{}},
  label={lst:rust-vec-macro}
]{}
#[macro_export]
macro_rules! vec {
  ( $( $x:expr ),* ) => {
    {
      let mut temp_vec = Vec::new();
      $(
        temp_vec.push($x);
      )*
      temp_vec
    }
  };
}
\end{lstlisting}
\footnotetext{\url{https://doc.rust-lang.org/stable/book/}}

\item
\textbf{Terra}

Terra\cite{terra} implements a very explicit metaprogramming model.
The language is based on LUA, and exploits the dynamic nature of the language
together with LLVM \gls{jit} compilation to allow code generation
to happen at runtime.
It implements multi-staged compilation and splicing just like MetaOCaml.

Listing \ref{lst:terra-addone} shows the definition of a metafunction that
returns a quoted expression that adds one to an element, which is then spliced
twice to generate a function called \lstinline{doit}.

\begin{lstlisting}[
  language=terra,
  caption={Definition of the \lstinline{addone} metafunction\protect\footnotemark{}},
  label={lst:terra-addone}
]{}
function addone(a)
    --return quotation that
    --represents adding 1 to a
    return `a + 1
end
terra doit()
    var first = 1
    --call addone to generate
    --expression first + 1 + 1
    return [ addone(addone(first)) ]
end
\end{lstlisting}
\footnotetext{\url{https://terralang.org/getting-started.html}}

Additionally, Terra can be embedded in other languages through its C API.
Overall it is a very versatile and experimental take on metaprogramming,
but the lack of interoperability with \cpp templates makes it hard to justify
its use for \gls{hpc} applications.

\item
\textbf{LGEN}

LGEN\cite{hpcs15}:
a compiler that produces performance-optimized
basic linear algebra computations on matrices
of fixed sizes with or without structure composed
from matrix multiplication, matrix addition, matrix
transposition, and scalar multiplication. Based on
polyhedral analysis using CLoog, the generated code
outperforms MKL and Eigen.

\end{itemize}

Other languages such as \textbf{Braid} \cite{braid} or
\textbf{Julia} \cite{julia} implement staged metaprogramming,
although Julia emits LLVM code directly, and Braid is unmaintained.

% TODO: Mini-conclusion, dire pourquoi on vise C++

\end{document}
