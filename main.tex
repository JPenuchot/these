%%%% Modèle proposé par kira.ribeiro@universite-paris-saclay.fr  %%%%
%%%% màj : 27/01/2023 %%%%

\documentclass[english,12pt,a4paper]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[default,oldstyle, scale=.95]{opensans}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{csquotes}
\usepackage{caption}
\captionsetup[figure]{font=small,labelfont=small}
\usepackage{xcolor}
\definecolor{Prune}{RGB}{99,0,60} % l14-33 : couleurs de la charte graphique upsaclay
\definecolor{B1}{RGB}{49,62,72}
\definecolor{C1}{RGB}{124,135,143}
\definecolor{D1}{RGB}{213,218,223}
\definecolor{A2}{RGB}{198,11,70}
\definecolor{B2}{RGB}{237,20,91}
\definecolor{C2}{RGB}{238,52,35}
\definecolor{D2}{RGB}{243,115,32}
\definecolor{A3}{RGB}{124,42,144}
\definecolor{B3}{RGB}{125,106,175}
\definecolor{C3}{RGB}{198,103,29}
\definecolor{D3}{RGB}{254,188,24}
\definecolor{A4}{RGB}{0,78,125}
\definecolor{B4}{RGB}{14,135,201}
\definecolor{C4}{RGB}{0,148,181}
\definecolor{D4}{RGB}{70,195,210}
\definecolor{A5}{RGB}{0,128,122}
\definecolor{B5}{RGB}{64,183,105}
\definecolor{C5}{RGB}{140,198,62}
\definecolor{D5}{RGB}{213,223,61}

\usepackage[absolute]{textpos}
\usepackage{appendix}
\usepackage{array}
\usepackage{biblatex}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{float}
\usepackage{geometry}
\usepackage{glossaries}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{mdframed}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{svg}
\usepackage{tikz}
\usepackage{titlesec}
\usepackage{xspace}

% \renewcommand{\FrenchLabelItem}{\textbullet}

% pour ne garder que les n°de page en milieu-bas
% et supprimer les indications de chapitre en marge haute
\pagestyle{plain}

% Fichiers biblio

\addbibresource{bibliography/biblio.bib}
\addbibresource{bibliography/comptime.bib}
\addbibresource{bibliography/ctbench.bib}
\addbibresource{bibliography/hpcs2018.bib}
\addbibresource{bibliography/metalanguages.bib}
\addbibresource{bibliography/metalibraries.bib}
\addbibresource{bibliography/parallelism.bib}
\addbibresource{bibliography/poacher.bib}
\addbibresource{bibliography/simd.bib}

% Commandes pour la these de Jules

\providecommand{\cpp}{\textsc{C++}\xspace}
\providecommand{\ctbench}{\textsc{ctbench}\xspace}
\providecommand{\eg}{\textit{e.g.}\xspace}
\providecommand{\grapher}{\textsc{grapher}\xspace}
\providecommand{\ie}{\textit{i.e.}\xspace}

\hypersetup{
  colorlinks=true, % toujours garder colorlinks=true
  linkcolor=black,
  urlcolor=A5
}

\lstset{
  frame=single,
  basicstyle={\ttfamily\footnotesize},
  numberstyle=\tiny\color{C1},
  keywordstyle=\color{B2},
  commentstyle=\color{D4},
  stringstyle=\color{A3},
  breaklines=true,
  tabsize=2,
  showstringspaces=false
}

\lstdefinelanguage{cmake}{
  morekeywords={STRING, BOOL, CACHE, REQUIRED},
  morecomment=[l]{\#},
  morestring=[b]"
}

\lstdefinelanguage{dlang}{
  morekeywords={static, if, typeof, int},
  morecomment=[l]{\#},
  morestring=[b]"
}

\lstdefinelanguage{rust}{
  morekeywords={let, mut, expr},
  morecomment=[l]{//},
  morestring=[b]"
}

\lstdefinelanguage{javascript}{
  morekeywords={},
  morecomment=[l]{},
  morestring=[b]"
}

\lstdefinelanguage{json}{
  morekeywords={},
  morecomment=[l]{},
  morestring=[b]"
}

\lstdefinelanguage{terra}{
  morekeywords={function, return, terra, end, var},
  morecomment=[l]{--},
  morestring=[b]"
}

\makeglossaries

\newglossaryentry{litval}{
  name=literal value,
  plural=literal values,
  description=A value that does not hold any pointer to dynamic memory.
}

\newglossaryentry{constexpr}{
  name=constexpr,
  description=A value or function that can be used in a constant expression.
}

\newglossaryentry{consteval}{
  name=constant evaluation,
  plural=constant evaluations,
  description=The evaluation of an expression that is performed at compile time.
}

\newglossaryentry{bf}{
  name=Brainfuck,
  description=empty
}

\newglossaryentry{ir}{
  name=intermediate representation,
  description=empty
}

\newglossaryentry{pbg}{
  name=pass by generator,
  description=empty
}

\newglossaryentry{tmp}{
  name=template metaprogramming,
  description=empty
}

\newglossaryentry{et}{
  name=expression template,
  description=empty
}

\newacronym{api}{API}{Application Programming Interface}
\newacronym{ast}{AST}{Abstract Syntax Tree}
\newacronym{avx}{AVX}{Advanced Vector Extensions}
\newacronym{blas}{BLAS}{Basic Linear Algebra Subprograms}
\newacronym{ctpg}{CTPG}{Compile Time Parser Generator}
\newacronym{ctre}{CTRE}{Compile Time Regular Expression}
\newacronym{dsel}{DSEL}{Domain-Specific Embedded Language}
\newacronym{dsl}{DSL}{Domain-Specific Language}
\newacronym{erb}{ERB}{Embedded Ruby}
\newacronym{gemv}{GEMV}{General Matrix Vector multiply}
\newacronym{hpc}{HPC}{High Performance Computing}
\newacronym{jit}{JIT}{Just-In-Time}
\newacronym{nttp}{NTTP}{Non-Type Template Parameter}
\newacronym{pcre}{PCRE}{Perl Compatible Regular Expression}
\newacronym{rpn}{RPN}{Reverse Polish Notation}
\newacronym{sfinae}{SFINAE}{Substitution Failure Is Not An Error}
\newacronym{tml}{TML}{Tiny Math Language}

\newacronym{cpu}{CPU}{Central Processing Unit}
\newacronym{gpu}{GPU}{Graphical Processing Unit}

\newacronym{mimd}{MIMD}{Multiple Instruction Multiple Data stream}
\newacronym{misd}{MISD}{Multiple Instruction Single Data stream}
\newacronym{simd}{SIMD}{Single Instruction Multiple Data stream}
\newacronym{sisd}{SISD}{Single Instruction Single Data stream}

\newacronym{numa}{NUMA}{Non-Unified Memory Architecture}
\newacronym{uma}{UMA}{Unified Memory Architecture}

% ==============================================================================
\usepackage{subfiles} % Garder a la fin

\begin{document}

\begin{titlepage}

%\thispagestyle{empty}

\newgeometry{left=6cm,bottom=2cm, top=1cm, right=1cm}

\tikz[remember picture,overlay]
\node[opacity=1,inner sep=0pt] at (-13mm,-135mm){
  \includegraphics{ups/frame.pdf}
};

%*****************************************************
%******** NUMÉRO D'ORDRE DE LA THÈSE À COMPLÉTER *****
%******** POUR LE SECOND DÉPOT                   *****
%*****************************************************

\color{white}

\begin{picture}(0,0)
\put(-152,-743){\rotatebox{90}{\Large \textsc{THESE DE DOCTORAT}}} \\
\put(-120,-743){\rotatebox{90}{NNT : 2020UPASA001}}
\end{picture}

%*****************************************************
%******************** TITRE **************************
%*****************************************************

\flushright
\vspace{10mm} % à régler éventuellement
\color{Prune}

\fontsize{22}{26}\selectfont
  \Huge Techniques avanc\'ees de g\'en\'eration de code pour la performance\\

\normalsize
\color{black}
\Large{\textit{Advanced techniques for high performance code generation}} \\
%*****************************************************


\fontsize{8}{12}\selectfont

\vspace{1.5cm}

\normalsize
\textbf{Thèse de doctorat de l'université Paris-Saclay} \\

\vspace{6mm}

\small École doctorale n$^{\circ}$580: sciences et technologies de l'information et de la communication (STIC)\\
\small Spécialité de doctorat: Informatique\\
\small Graduate School: Informatique et sciences du numérique. Référent: Faculté des sciences d’Orsay\\
\vspace{6mm}

\footnotesize Thèse préparée dans l'unités de recherche
\textbf{Université Paris-Saclay, CNRS, Laboratoire interdisciplinaire des sciences du numérique, 91405, Orsay, France}, sous la direction de \textbf{Joel FALCOU},
Maître de conférences\\
\vspace{15mm}

\textbf{Thèse soutenue à Paris-Saclay, le JJ mois AAAA, par}\\
\bigskip
\Large {\color{Prune} \textbf{Jules P\'ENUCHOT}}

%************************************
\vspace{\fill} % ALIGNER LE TABLEAU EN BAS DE PAGE
%************************************

\bigskip

\flushleft
\small {\color{Prune} \textbf{Composition du jury}}\\
{\color{Prune} \scriptsize {Membres du jury avec voix délibérative}} \\
\vspace{2mm}
\scriptsize
\begin{tabular}{|p{7cm}l}
\arrayrulecolor{Prune}
\textbf{Christine PAULIN-MOHRING} & Pr\'esidente \\
Professeure des universit\'es, Universit\'e Paris-Saclay & \\
\textbf{David HILL} & Rapporteur \& Examinateur \\
Professeur des universit\'es, Universit\'e Clermont-Auvergne & \\
\textbf{Thierry G\'ERAUD} & Rapporteur \& Examinateur \\
Professeur des universités, EPITA Research Laboratory & \\
\textbf{Christine PAULIN-MOHRING} & Examinatrice \\
Professeure des universit\'es, Universit\'e Paris-Saclay & \\
\textbf{Amina GUERMOUCHE} & Examinatrice \\
Ma\^itresse de conf\'erences, Affiliation & \\

\end{tabular}

\end{titlepage}

\chapter*{Remerciements}

Merci \`a \textbf{Christine Paulin} d'assurer la pr\'esidence du jury,
aux rapporteurs \textbf{David Hill} et \textbf{Thierry G\'eraud},
ainsi qu'\`a \textbf{Amina Guermouche} d'examiner la th\`ese avec
Christine Paulin.

Je tiens \'egalement \`a faire part de ma reconnaissance envers
\textbf{Christine Paulin-Mohring} pour la cr\'eation du Magist\`ere d'Informatique
qui m'a permis de d\'ecouvrir la recherche dans un cadre tr\`es privil\'egi\'e.

Merci \'egalement \`a \textbf{Jean-Thierry Laprest\'e} et
\textbf{Daniel \'Etiemble} pour leurs relectures.

Merci, bien s\^ur, \`a \textbf{Jo\"el Falcou}, pour son accompagnement
bienveillant, valorisant, et d\'evou\'e depuis mon premier stage de recherche.

% Merci les collegues et les parents

Merci \`a \textbf{Amal Khabou}, dont l'aide m'a \'et\'e pr\'ecieuse pour la pr\'eparation
de ma premi\`ere conf\'erence.

Merci \`a \textbf{Hartmut Kaiser}, pour son accueil \`a LSU,
\textbf{Adrian et Cory Lemoine}, qui m'ont aid\'e \`a
traverser un \'ev\'enement difficile et marquant pendant mon s\'ejour,
et bien s\^ur \textbf{au reste de l'\'equipe Ste||ar} pour les amiti\'es
que j'ai pu y nouer, et la gentillesse de chaque personne que j'y ai
rencontr\'ee.

Merci \`a \textbf{Paul Keir}, pour sa collaboration amicale et bienveillante.

Merci \`a \textbf{mes parents},
pour m'avoir transmis la passion de l'informatique,
pour m'avoir soutenu \`a tout \^age,
y compris pendant mes ann\'ees de th\`ese.

% Merci les potes

\textbf{Antoine Lanco et Alexandrina Korneva}, pour leur camaraderie, les
d\'ecorations de f\^etes, les f\^etes dans les champs, et les champs de pizzas.

\textbf{Marie Debard}, pour son soutien moral lorsque je m'inqui\'etais
pour le financement de ma th\`ese.

% page des résumés à garder en 2ème page.
% Si les résumés sont trop longs pour tenir sur une seule et même page,
% on peut mettre un résumé par page
\thispagestyle{empty}
\newgeometry{top=1.5cm, bottom=1.25cm, left=2cm, right=2cm}

\noindent
\includegraphics[height=2.45cm]{ups/logo_STIC.png}
\vspace{1cm}
%*****************************************************

\small

\begin{mdframed}[linecolor=Prune,linewidth=1]

\textbf{Titre:} Techniques avanc\'ees de g\'en\'eration de code pour
la performance

\noindent \textbf{Mots clés:}
M\'etaprogrammation, compilation, C++, HPC, parall\'elisme, constexpr, SIMD,
optimisation, programmation g\'en\'erique, programmation g\'en\'erative,
templates, langage d\'edi\'e

\vspace{-.5cm}
\begin{multicols}{2}
\noindent \textbf{Résumé:}
En r\'eponse \`a la demande croissante de puissance de calcul,
les constructeurs de mat\'eriel proposent de nouvelles architectures
parall\`eles de tr\`es diff\'erentes natures, et ayant chacune leurs propres
API et mod\`ele de programmation.

Cela rend les applications haute performance plus complexes \`a d\'evelopper
avec des m\'ethodes de programmation traditionnelles, d'autant plus lorsque
plusieurs architectures sont cibl\'ees.

En r\'eponse \`a cette demande, des biblioth\`eques exploitant la
g\'en\'eration de code \`a la compilation furent d\'evelopp\'ees pour faciliter
la programmation haute performance avec des abstractions de haut niveau tels
que les langages d\'edi\'es externes.

Dans cette th\`ese, nous explorons en premier temps les techniques de
m\'etaprogrammation existant \`a travers un large panel de langages, puis nous
\'evaluons les techniques actuelles de m\'etaprogrammation de templates C++
dans le cadre de la g\'en\'eration de noyaux de calculs de type BLAS.

Nous couvrons ensuite de nouvelles techniques de m\'etaprogrammation bas\'ees
sur l'ex\'ecution de code C++ \`a la compilation en impl\'ementant des parsers
pour deux langages: Brainfuck, et un langage appel\'e Tiny Math Language (TML).
Le parser Brainfuck est fourni avec plusieurs backends de g\'en\'eration de code
pour \'etudier diff\'erentes techniques de g\'en\'eration de code, tandis que
TML est utilis\'e pour \'etudier la g\'en\'eration de code en utilisant des
biblioth\`eques portables haute performance.

Pour \'evaluer l'impact de ces diverses techniques de m\'etaprorgammation,
nous proposons une nouvelle m\'ethodologie de benchmarking qui exploite
le profiler int\'egr\'e de Clang, ce qui permet l'analyse de performance
en temps de compilation au-del\`a des mesures de performance en bo\^ite noire.

\end{multicols}

\end{mdframed}

\clearpage

\thispagestyle{empty}
\newgeometry{top=1.5cm, bottom=1.25cm, left=2cm, right=2cm}

\noindent
\includegraphics[height=2.45cm]{ups/logo_STIC.png}
\vspace{1cm}
%*****************************************************

\small
\begin{mdframed}[linecolor=Prune,linewidth=1]

\textbf{Title:} Advanced techniques for high performance code generation

\noindent \textbf{Keywords:}
Metaprogramming, compilation, C++, HPC, parallelism, constexpr, SIMD,
optimization, generic programming, generative programming,
templates, domain-specific language

\begin{multicols}{2}
\noindent \textbf{Abstract:}
As a response to an increasing demand for computing performance,
hardware manufacturers propose new parallel hardware architectures
of very different nature, each with their own API and programming model.
This makes high performance applications more complex to develop
with traditional programming practices, especially when multiple architectures
are targeted.

As a response, libraries leveraging compile-time code generation were developed
to facilitate portable high performance programming with high level abstractions
such as Domain-Specific Embedded Languages (DSELs).

In this thesis, we first explore existing metaprogramming practices across
a wide variety of languages, then evaluate current C++ template metaprogramming
techniques in the framework of BLAS-like kernel generation.

We then cover new metaprogramming techniques based on compile-time
C++ code execution by implementing compile-time parsers for two languages:
Brainfuck, and a language called Tiny Math Language (TML).
The Brainfuck parser is provided with several code generation backends
to study and compare different code generation techniques, whereas TML is used
to study code generation using portable high performance computing libraries.

In order to assess the compile-time impact of these various metaprogramming
techniques, we propose a new benchmarking methodology that uses
Clang's built-in profiler, enabling compile-time performance scaling analysis
beyond black-box benchmarking.
\end{multicols}
\end{mdframed}

\titleformat{\chapter}[hang]{\bfseries\Large\color{Prune}}{\thechapter\ -}{.1ex}
{\vspace{0.1ex}}[\vspace{1ex}]\titlespacing{\chapter}{0pc}{0ex}{0.5pc}

\titleformat{\section}[hang]{\bfseries\normalsize}{\thesection\ .}{0.5pt}
{\vspace{0.1ex}}[\vspace{0.1ex}]\titlespacing{\section}{1.5pc}{4ex plus .1ex minus .2ex}{.8pc}

\titleformat{\subsection}[hang]{\bfseries\small}{\thesubsection\ .}{1pt}
{\vspace{0.1ex}}[\vspace{0.1ex}]\titlespacing{\subsection}{3pc}{2ex plus .1ex minus .2ex}{.1pc}

\newgeometry{top=4cm, bottom=4cm, left=2cm, right=2cm}

\tableofcontents

\newgeometry{top=4cm, bottom=4cm, left=4cm, right=4cm}

% ------------------------------------------------------------------------------
% Commandes pour la these de Jules

% ------------------------------------------------------------------------------
% These de Jules

\subfile{french-condensed.tex}

\part{
  Metaprogramming for High Performance Computing
}

\chapter*{
  Introduction
}

\subfile{introduction.tex}

\chapter{
  Metaprogramming
}

In this chapter, I will first give an overview of metaprogramming in
various languages. Then I will focus on the state of the art
of \cpp metaprogramming, and finally give examples of applications
of such techniques being used in the context of \gls{hpc} libraries.

\subfile{1-current-metaprogramming/1-metaprog-and-hpc-overview.tex}
\subfile{1-current-metaprogramming/2-cpp-constructs.tex}

\section{
  Conclusion
}

Metaprogramming surfaced in many forms and in many languages such as Lisp or C
macros, long before \cpp templates came to exist.
It still persists as an advanced but widespread practice across many languages,
ranging from basic preprocessing to dynamic code generation and compilation.

Template metaprogramming has been the de facto standard for \cpp metaprogramming
as many libraries use it to implement high performance or highly specialized
libraries that benefit from compile-time evaluation and code generation.
This is especially true for \gls{hpc} libraries that benefit the most from
partial evaluation.

The language \cpp later evolved to provide host language availability for
metaprogramming with the introduction and evolution of \gls{constexpr}
programming, similar to what Lisp macros have been pioneering.
This new way of writing \cpp metaprograms will be explored throughout
the second part of this thesis. Meanwhile, we are going to investigate the
actual benefits of such techniques by applying them to the basic building blocks
of \gls{hpc} applications: linear algebra kernels.

\chapter{
  Code generation at low level
}

\subfile{1-current-metaprogramming/3-gemv.tex}

\part{
  C++ metaprogramming beyond templates
}

\chapter{
  Compile time benchmarking methodology
}

With \gls{tmp} libraries like Eigen\cite{eigen}, Blaze\cite{blazelib},
or CTRE \cite{ctre} becoming more widespread,
there is an increasing interest for compile time computation.
These needs might grow
even larger as \cpp embeds more features over time to support and extend this
kind of practices, like compile time containers \cite{more-constexpr-containers}
or static reflection\cite{static-reflection}. However, there is still no clear
cut methodology to compare the performance impact of different metaprogramming
strategies.
As new \cpp features allow for new techniques with alleged
better compile time performance, no scientific process can back up those claims.

In this chapter, I introduce \textbf{ctbench}, which is a set of tools for
compile time benchmarking and analysis in \cpp. It provides developer-friendly
tools
to define and run benchmarks, then aggregate, filter out, and plot the data to
analyze them. As such, \ctbench aims to be a foundational layer of a proper
scientific methodology for analyzing compile time program behavior.
\\

ctbench puts an emphasis on software quality.
The goal was not just to develop a plotting tool for a single
compilation time analysis, but to provide a repeatable process
along with a robust implementation to improve compilation time
performance analysis as a whole.

% The use of a GitHub CI for building and testing the project guarantees that
% project remains functional at all times on all supported platforms.
% As of writing, the project is continuously built and tested for Ubuntu 23.04
% and Arch Linux. The test environment is fully reproducible as well thanks to
% the use of Docker for its setup.

\ctbench was presented at CPPP 2021 \cite{ctbench-cppp21},
and at Meeting \cpp 2022 \cite{meetingcpp22}. It was also published
at the Journal of Open Source Science \cite{Penuchot2023}. It is currently
available as an open source
project\footnote{\url{https://github.com/jpenuchot/ctbench}} and as a package
through the Arch User
Repository\footnote{\url{https://aur.archlinux.org/packages/ctbench-git}}
and vcpkg\footnote{\url{https://vcpkg.io/en/packages}}.

\subfile{2-compilation-time-analysis/1-state-of-the-art.tex}
\subfile{2-compilation-time-analysis/2-ctbench-design.tex}
\subfile{2-compilation-time-analysis/3-ctbench-in-action.tex}

\clearpage%

\section{
  Conclusion
}

Deep analysis of compile time scaling becomes necessary to understand
compile time performance of metaprogramming techniques.
Until now, no tool was really able to combine the depth of profiling data
analysis with variable size compile time benchmarking.
Moreover, there was no tool that could really fit in scientific work
where reproductibility is a necessity.

ctbench answers that need as a simple, powerful, and extensible
open-source solution that is peer-reviewed and distributed as a reusable
software package.

Such level of detail and granularity in the analysis of compile-time benchmarks
was never reached before, and may help us set better practices to improve the
compile-time performance of metaprograms, and give better insight on compiler
performance as well.

\chapter{
  Constexpr parsing for HPC
}
% \begin{abstract}
% Design of high performance, high abstraction libraries in \cpp often take
% advantages of techniques like template metaprogramming or \glspl{et}
% to design \glspl{dsel}. However, such techniques are limited by the natural syntax
% of \cpp. In this thesis, we explore the benefits of using \cpp23 compile time
% computation features to provide compile time string based \glspl{dsel} that can then
% use arbitrary syntax.
% \end{abstract}

\section{Introduction}

\cpp is often touted as a \textit{Zero-Cost Abstraction} langage due to some of
its design philosophy and its ability to compile high level abstractions into
very efficient binary code. Some more radical techniques can be used to
force the compiler to interpret \cpp code as a \gls{dsel}.

In the field of \acrlong{hpc}, \cpp users are often driven to use
libraries built on top of those idioms like Eigen\cite{eigen} or
Blaze\cite{blazelib,iglberger2012_2}. They all suffer from a major limitation:
by being tied to the natural \cpp syntax, they can't express nor embed arbitrary
languages.

In this chapter, we try to demonstrate that the new features of \cpp23 related
to compile time programming are able to help developers designing \glspl{dsel}
with arbitrary syntax by leveraging \gls{constexpr} computations, compile time
dynamic objects and lazy evaluation through lambda functions.
After contextualizing our contribution in the general \glspl{dsel} domain,
this chapter will explain the core new techniques enabled by \cpp23
and how we can apply to build two different \glspl{dsel} with their own
non-\cpp syntax. We'll also explore the performances of those \glspl{dsel}
in term of compile time to assess their usability in parallel programming.

\subfile{3-new-approaches-to-metaprogramming/1-technical-background.tex}
\subfile{3-new-approaches-to-metaprogramming/2-constexpr-codegen-techniques.tex}

\chapter{
  Applied constexpr parsing
}

Now that the idea of using \gls{constexpr} functions to generate code
was proven to work, it is time to put it into practice and observe
the viability of its integration in a high performance computing
development cycle.

I will present two examples in this chapter:
the first one is a \gls{constexpr} Brainfuck parser that serves as a simple
use case for experimenting different methods to generate code from
\gls{constexpr} \glspl{ast}.

These observations guided the implementation of the second example, which is a
\gls{constexpr} parser for simple math languages. If features a code generation
backend that supports high performance code generation via Blaze.

\subfile{3-new-approaches-to-metaprogramming/3-brainfuck.tex}
\subfile{3-new-approaches-to-metaprogramming/4-math-parsing.tex}

\section{Conclusion}

The Brainfuck example shows that using \gls{constexpr} programming to embed
large programs written in foreign languages in \cpp can be achieved.
\gls{ast} serialization makes it possible to store parsing results
and avoid running into quadratic compilation time issues, as long as
the code generation methods being .

The case of \gls{tml} also shows that \gls{ast} serialization
by itself is not a magic bullet to avoid running into compilation time
scaling issues.
The compilation time offset of \gls{tml} parsing, despite being reasonable
within the bounds of expected use cases for \gls{tml}, was quadratic.

These results show that more effort is needed to determine which metaprogramming
techniques should be avoided to avoid runaway compilation times,
and how \cpp library code or modifications to the \cpp language itself
could facilitate scalable code generation from \gls{constexpr} function results.

\chapter*{Conclusion \& perspectives}

In the first part we have shown that metaprogramming is a widespread practice,
and that it is still evolving across many languages with \cpp continuously
evolving on that front, while being the most comprehensive platform for
parallel computing.
We then demonstrated that code generation is a viable option to greatly reduce
the implementation complexity of high performance linear algebra kernels,
while still providing similar, or even higher level of performance.
These results reinforce the hypothesis that metaprogramming can be used to
tackle the challenge of portability in the context of \acrlong{hpc},
even for very low level tasks where the reduction of abstraction overhead
is critical to achieve decent performance.

Before moving on to \gls{constexpr} programming, we adressed the lack of
tools for the scientific study of compilation times with ctbench.
We proposed a new compile-time study methodology based on Clang's built-in
profiler that help us understand the impacts of metaprograms on each step
of the compilation process. While it offers limited benchmarking capabilities
when used with GCC as the latter does not output any detailed profiling data,
conclusions drawn on Clang might be relevant for GCC, even if they are not
directly transposable.

Then we demonstrated that using \gls{constexpr} code to
implement embedded language parsers for in \cpp23 is possible despite
limitations on \gls{constexpr} memory allocation, and that doing so is possible
with reasonable impact on compilation times.

The Brainfuck example shows that code generation backends are
a determining factor for embedded compiler performance,
and if implemented correctly, a code generator can provide
adequate scaling for embedding large programs.
More specifically, we have shown that code generation backends must rely on
value-based metaprogramming in favor of type-based metaprogramming to achieve
decent compile time performance scaling. However, using value-based
metaprogramming for code generation might require additional implementation
efforts, and backends based on the \gls{pbg} technique might be a better fit
for quick \gls{dsel} prototyping.

On the other hand, the \gls{tml} example demonstrated the interoperability
between \gls{constexpr} programming and existing high performance libraries
relying on \glspl{et}. It also showed that using value-based representations for
code generation is not always trivial as the use of tuples was necessary to
store partial results during the code generation phase.
\\

Allowing the direct use of \gls{constexpr} allocated memory as \acrlongpl{nttp}
could help greatly reduce the implementation complexity of compile-time code
generators, and improve their performance as well by removing the requirement
for additional serialization steps or compile time heavy workarounds such as
\gls{pbg}.
Another way forward could also be the development of reflection and slicing
capabilities for \cpp, or an imperative-style code generation \gls{api}.

In the meantime, developing \gls{constexpr} serialization libraries could
greatly help with the development of performant code generation backends
as it would reduce the development effort to use more performant code generation
methods, and could be achievable without waiting for a new \cpp release.

% TODO: Talk about faer

% \textbf{faer} \cite{faer}
%
% \begin{lstlisting}[
%   language=c++
% ]{}
% use faer::{mat, Mat, prelude::*};
%
% // empty 0x0 matrix
% let m0: Mat<f64> = Mat::new();
%
% // zeroed 4x3 matrix
% let m1: Mat<f64> = Mat::zeros(4, 3);
%
% // 3x3 identity matrix
% let m2 = Mat::from_fn(
%   3, 3,
%   |i, j| if i == j { 1.0 } else { 0.0 });
%
% // 4x2 matrix with custom data
% let m3 = mat![
%     [4.93, 2.41],
%     [5.43, 4.33],
%     [9.83, 1.59],
%     [7.13, 5.02_f64],
% ];
%
% // compute the qr decomposition of a matrix
% let qr_decomposition = m3.qr();
% \end{lstlisting}


\clearpage
\printglossaries

\clearpage
\printbibliography

\begin{appendices}
\chapter{Appendix}
\end{appendices}

\appendix

\subfile{3-new-approaches-to-metaprogramming/appendix.tex}

\end{document}
