\documentclass[../main]{subfiles}
\begin{document}

% NOTE: The RPN notation was already introduced

\section{
  Math parsing and high performance code generation
}

Thanks to the previous experiments, we know that using serialized structures
as \glspl{nttp} is preferable to keep compilation times lower.
As such, we will be generating code from mathematical expressions using
a parsing algorithm that transforms infix formulas into their \gls{rpn}
representation.

In \ref{lbl:codegen-from-rpn}, we already demonstrated that generating code
from \gls{rpn} formulas is a rather easy task, therefore this section
will only cover the Shunting Yard algorithm, and the use of \gls{rpn}
code generation applied to high performance computing.

\subsection{
  The Shunting-Yard algorithm
}

As parsing algorithms and \gls{constexpr} dynamic data representations were
already covered in \ref{lbl:bf-parsing-and-codegen}, the implementation of
the Shunting Yard algorithm will not be covered in detail here.
A thoroughly commented \gls{constexpr} implementation is available in appendix
\ref{app:shunting-yard-impl}. It features the algorithm itself, as well as
data structures it relies on, and higher order helper functions
for code generation.

The working principle of the algorithm is rather simple:
an operator and an operand stack are read in order, and moved
from the input list to the output queue and the operator stack.
If an operator of lower precedence than the operator on top of the
operator stack is read, then the operator stack is dumped in the output queue.
The worst case time and memory complexity of the algorithm is $O(N)$.

Once again, code generation from postfix notation formulas was already covered
in \ref{lbl:codegen-from-rpn}, so we will skip straight to the use of Blaze
to generate high performance code from \gls{constexpr} formulas.

\subsection{
  Using Blaze for high performance code generation
}

All the technical aspects of high performance code generation from
\gls{constexpr} \glspl{dsel} in \cpp23 have been covered and implemented
individually so far:
a \gls{constexpr} Shunting Yard parser for math formulas,
a code generator for \gls{rpn} formulas,
and an optimizing library for math computation (the Blaze library).

I will now demonstrate that all these layers can work together
as a complete high performance compilation chain for a math \glspl{dsel}.
I will start by introducing a simple demonstrator language: \gls{tml}.
It is a very basic language for simple math that can read math formulas
containing integers, \lstinline{x} and \lstinline{y} variables,
\lstinline{sin} and \lstinline{max} functions, a small set of infix operators
(\lstinline{+}, \lstinline{-}, \lstinline{*}, \lstinline{/}, \lstinline{^}),
as well as \lstinline|{}| and \lstinline{()} as parenthesis pairs.

Using the Sunting Yard implementation from
appendix \ref{app:shunting-yard-impl}, we can specify variable identifiers,
function identifiers, infix operators (with precedence), and parenthesis
as shown in listing \ref{lst:tml-parser} to define a simple math language
that can be parsed by a \gls{constexpr} function.

We will now oversee the code generation implementation.
As a quick reminder, generating code from a \gls{rpn} formula
consists in reading tokens one by one, stacking operands, and consuming
them as needed. The stack is implemented with a \lstinline{kumi::tuple} object,
which is an enhanced version of \lstinline{std::tuple}.

Each operand in the tuple is a function that takes \lstinline{x} and
\lstinline{y} parameters and returns an arbitrary value.
As such, operands have a form similar to the function
objects shown in listing \ref{lst:tml-operands}.
The parameters are not used by the \lstinline{forty_two} operand,
the \lstinline{x} operand simply forwards the first parameter,
and the \lstinline{plus} operand forwards the parameters to its sub-operands.

\clearpage%

\begin{lstlisting}[
  language=c++,
  caption=\gls{tml} parser implementation,
  label=lst:tml-parser
]{}
constexpr shunting_yard::parse_result_t
parse(std::string_view const &formula) {
  namespace sy = shunting_yard;

  sy::token_specification_t tiny_math_language_spec{
      .variables =
          {
              sy::variable_t("x"),
              sy::variable_t("y"),
          },
      .functions =
          {
              sy::function_t("sin"),
              sy::function_t("max"),
          },
      .operators =
          {
              sy::operator_t("+", sy::left_v, 10),
              sy::operator_t("-", sy::left_v, 10),
              sy::operator_t("*", sy::left_v, 20),
              sy::operator_t("/", sy::left_v, 20),
              sy::operator_t("^", sy::right_v, 30),
          },
      .lparens = {sy::lparen_t("("), sy::lparen_t("{")},
      .rparens = {sy::rparen_t(")"), sy::rparen_t("}")}};

  return parse_to_rpn(formula, tiny_math_language_spec);
}
\end{lstlisting}

\begin{lstlisting}[
  language=c++,
  caption=\gls{tml} operand examples,
  label=lst:tml-operands
]{}
/// Operand representing the 42 constant
auto forty_two = [](auto const &, auto const &) {
  return 42;
};

/// Operand representing the x variable
auto x = [](auto const &input_x,
            auto const &) -> auto const & {
  return input_x;
};

/// Operand representing the plus operator
auto plus = [operand_a, operand_b](auto const &input_x,
                                   auto const &input_y) {
  return operand_a(input_x, input_y) +
         operand_b(input_x, input_y);
};
\end{lstlisting}

\clearpage%

The result of the code generation is a function that takes two elements of
arbitrary type as an input, and performs the operations on them.
Listing \ref{lst:tml-usage} shows how to generate code from a formula
and use the generated function to perform operations on Blaze vectors.
We use this code to verify the validity of the result.

\begin{lstlisting}[
  language=c++,
  caption=\gls{tml} usage example,
  label=lst:tml-usage
]{}
int main() {
  namespace tml = tiny_math_language;

  static constexpr auto formula =
      "sin((x + 3) / 3 * y ^ 2)";

  // Runtime parsing prints parsing steps
  // for debugging
  tml::parse(formula);

  // Input vectors
  constexpr std::size_t vec_size = 16;
  blaze::DynamicVector<double> vector_x(vec_size, 1.),
      vector_y(vec_size, 12.);

  // Generating code from the formula
  auto function = tml::codegen<formula>();

  // Running the generated code
  blaze::DynamicVector<double> result =
      function(vector_x, vector_y);

  // Printing and verifying the result
  double const expected_value =
      std::sin((1. + 3.) / 3. * std::pow(12., 2.));
  for (double const &element : result) {
    fmt::println("{}", element);
    if (std::abs(element - expected_value) > 0.01) {
      throw;
    }
  }
}
\end{lstlisting}

We also verify that the expression \lstinline{function(vector_x, vector_y)}
generates the right Blaze expression template by compiling the code in
listing \ref{lst:tml-blaze-typecheck}. The \lstinline{static_assert}
expression will not compile if the generated type is not the same as
\lstinline{expected_type}.

\clearpage%

\begin{lstlisting}[
  language=c++,
  caption=Result type checking for generated function output,
  label=lst:tml-blaze-typecheck
]{}
using namespace blaze;

using expected_type = DVecMapExpr<
    DVecScalarMultExpr<
        DVecDVecMultExpr<
            DVecMapExpr<
                DynamicVector<float, false,
                              AlignedAllocator<float>,
                              GroupTag<0>>,
                Bind2nd<Add, float>, false>,
            DVecMapExpr<
                DynamicVector<float, false,
                              AlignedAllocator<float>,
                              GroupTag<0>>,
                Bind2nd<Pow, float>, false>,
            false>,
        float, false>,
    Sin, false>;

static_assert(
    std::is_same<expected_type,
                 decltype(function(vector_x,
                                   vector_y))>::value);
\end{lstlisting}

\subsection{
  Studying the compilation time overhead of parsing
  for high performance code generation
}

A question remains about the use of compile time math parsing
for high performance code generation: what is the compilation time impact?
To answer that question, I will again measure compilation times for benchmarks
representing what would be a "realistic" use case in terms of size,
and simpler synthetic benchmarks to study the scaling of the
performance overhead as math formula sizes increase.

% A "realistic" use case

For the "realistic" use case, we will simply consider the formula from
listing \ref{lst:tml-usage} and measure the compiler execution time
with and without compile time parsing to generate a Blaze expression.
In one measurement where we compile a \gls{tml} formula into its evaluation
via Blaze, we observe a compilation time of 5.94 seconds.
In another one where we compile the same formula using the Blaze API directly
and without including the \gls{tml} header, the measured compilation time is
5.62 seconds.

These initial measurements show that a 6\% compile time overhead when using
the \gls{tml} parser on top of Blaze.
However, to better understand the impact of this method at scale,
we need to run variable size benchmarks to study more than a single use case.

\clearpage%

\begin{lstlisting}[
  language=c++,
  caption=Benchmark case: Blaze with \gls{tml} parsing,
  label=lst:blaze-bench-with-tml
]{}
#include <boost/preprocessor/repetition/repeat.hpp>
#include <blaze/Blaze.h>
#include <tiny_math_language.hpp>

// Generating a series of additions
#define REPEAT_STRING(z, n, str) str
static constexpr const char *program_string =
    BOOST_PP_REPEAT(BENCHMARK_SIZE, REPEAT_STRING,
                    "x + y + ") "x";

/// Benchmark entry point.
template <typename T = void> inline auto bench_me() {
  blaze::DynamicVector<unsigned int> vector_a(32, 12);
  blaze::DynamicVector<unsigned int> vector_b(32, 12);

  blaze::DynamicVector<unsigned int> res =
      tiny_math_language::codegen<program_string>()(
          vector_a, vector_b);

  return res;
}

void foo() { bench_me(); }
\end{lstlisting}

Listing \ref{lst:blaze-bench-with-tml} introduces a variable size benchmark
where a \gls{tml} formula is generated from a size factor $N$.
The formula consists in adding \lstinline{x} and \lstinline{y} terms $N$ times
to \lstinline{x}. The formula is then parsed to generate a \cpp function.

\lstinline{vector_a} and \lstinline{vector_b} are then fed to the generated
function to generate a Blaze expression, which is assigned to a Blaze vector.

\begin{lstlisting}[
  language=c++,
  caption=Benchmark case: Blaze without \gls{tml} parsing,
  label=lst:blaze-bench-without-tml
]{}
template <typename T = void> inline auto bench_me() {
  blaze::DynamicVector<unsigned int> vector_a(32, 12);
  blaze::DynamicVector<unsigned int> vector_b(32, 12);

  blaze::DynamicVector<unsigned int> res =
      BOOST_PP_REPEAT(BENCHMARK_SIZE, REPEAT_STRING,
                      vector_a + vector_b +) vector_a;

  return res;
}
\end{lstlisting}

Listing \ref{lst:blaze-bench-without-tml} shows an equivalent code
where the parsing part is skipped. This will serve as a baseline to study
the compile time overhead of \gls{tml} parsing.

Finally, a third benchmark case is added that consists in parsing
the same \gls{tml} formulas but without using Blaze for code generation.
Instead, the Blaze vectors are replaced with simple integers.

ctbench is used to instantiate, compile, and plot the compilation times
of these three benchmark cases with $N$ going from 0 to 20, ie. with formulas
having from one final term (\lstinline{vector_a} alone), to 41 final terms
(the subexpression \lstinline{vector_a + vector_b} contains 2 final terms,
and it is being added up to 20 times to \lstinline{vector_a}).

The benchmark cases are named as follows:

\begin{itemize}
\item \lstinline{formula-blaze} designates the case where \gls{tml} is parsed
to generate high performance code with Blaze,
\item \lstinline{no-formula-blaze} designates the case where Blaze is being used
to generate high performance directly (\ie without \gls{tml} parsing),
\item \lstinline{formula-no-blaze} designates the case where \gls{tml} is used
to generate code without Blaze but with integers instead.
\end{itemize}

% TODO: refaire avec des points?
\begin{figure}[h]
% \fontsize{8}{10}\selectfont
\includesvg[width=\textwidth]{images/shunting-yard.addition-series}
\caption{Parsing and code generation benchmarks}
\label{fig:tml-ctbench}
\end{figure}

Looking at the results of the benchmarks shown in figure \ref{fig:tml-ctbench},
we can make the following observations:

\begin{itemize}

\item
The \lstinline{formula-no-blaze} case seems to have a quadratic complexity,
although it has the shortest compilation time of all three cases until $N$
reaches 16 (\ie when the formula contains 33 final terms).
After this point, the compile time offset of \gls{tml} parsing becomes larger
than the Blaze code generation itself.

\item
The \lstinline{no-formula-blaze} case scales almost linearly with pretty low
scaling factor, but it starts at almost 5 seconds.
This is to be expected since Blaze has a very large code base.
To put Blaze's code base in perspective, its package in the Arch Linux
repositories weighs more than 34MiB, and it only contains \cpp header files.

\item
The \lstinline{formula-blaze} case looks pretty close to what we would expect:
it starts slightly above \lstinline{no-formula-blaze} and follows a scaling
pattern similar to \lstinline{formula-no-blaze}.

\end{itemize}

The compilation times on these benchmark cases remain under 20 seconds
within the range of our measurements, which covers cases assumably larger
than most use cases for the Blaze library.
Moreover, math formulas can be divided in subexpressions in an effort to
make a program clearer, or simply to mitigate the quadratic complexity
of \gls{tml} code generation.

Overall, this prototype \gls{dsel} proves the viability of compile time parsing
for high performance code generation in \cpp23 using as little type-based
metaprogramming as possible.
However \gls{tml} code generation does not scale as well as Brainfuck
code generation using the Flat backend, which scaled linearly as shown in
\ref{lbl:bf-large-program-benches}. A hypothesis for this higher complexity
is the cost induced by the tuple operations during the code generation step.

\end{document}
