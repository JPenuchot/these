\documentclass[main]{subfiles}
\begin{document}

This thesis is about metaprogramming techniques for parallel code generation.
It aims to study the boundary between compile-time parsing of
\glspl{dsel} and high performance code generation in \cpp.

The main motivation is to provide tools, libraries, and guidelines for embedding
mathematical languages in \cpp with the hope that it can be useful to build a
cohesive set of tools to make generic \gls{hpc} more accessible
to non-expert audiences. This goal is even more important as new computing
architectures emerge over time. Developing high performance programs requires
tuned implementations that can be achieved by either specializing
implementations for the target platforms, or using libraries that provide
specialized abstractions at various levels and for various domains.

Years after its introduction, Moore's law is still doing alive and well:
transistor count is still doubling every year despite people claiming
it is not alive anymore. This is due to a common confusion between
transistor count and computing power. While transistor count has been steadily
increasing, the throughput computing performance of single \gls{cpu} cores
has not.
This lead to the conclusion that "free lunch" is over, and future
high performance applications must adapt to increasingly parallel architectures
to increase compute throughput \cite{concurrency-revolution}.

Flynn's taxonomy \cite{flynn-taxonomy} describes four well known categories
to describe serial and parallel computer architectures:

\begin{itemize}
\item
\textbf{\gls{mimd}}, which consists in having several processors or cores
executing different proccesses. This category of parallelism itself has several
sub-categories depending on the memory topology:

  \begin{itemize}
  \item \textbf{Shared memory}, where processing units share a single
  pool of memory. Multi-threading is an example of such a topology as
  CPU cores share the same pool of RAM.
  \item \textbf{Distributed memory}, where processing units have their own
  memories and cannot access other memory pools.
  \item \textbf{Distributed shared memory}, where processing units have their
  own memory pools and can access other memory pools indirectly.
  \end{itemize}

\item
\textbf{\gls{misd}}, which is primarily used for fault tolerance by having
execution redundancy.

\item
\textbf{\gls{simd}}, which is a parallelism that can be implemented inside
a single \gls{cpu} core by having vector registers. These registers can hold
several values, and single instructions can operate on the vectors themselves.

\item
\textbf{\gls{sisd}}, where a computer only has a single processor with no
vector registers.

\end{itemize}

This is just a high level overview of the new computer architecture landscape
high performance software engineers have to navigate in.
In an ideal world, every architecture within the same category
should be programmable with same languages, tools, and libraries.
But in reality, hardware architectures within a same category
cannot run the same programs.
For example, CUDA is not compatible with AMD \glspl{gpu}, \gls{avx} instructions
are not available on ARM processors, oneAPI \gls{gpu} libraries developed by
Intel are not compatible with its competitors' hardware, and so on.

To adapt to this variety of hardware and \glspl{api}, new abstractions
were developed in the form of software libraries, compiler extensions,
and even programming languages to help build portable high performance
applications.

% TODO - Qu'est-ce que la generation de code/metaprog

% TODO - Quels sont les grands outils (citer les rapporteureuses)?

% TODO - on en vient aux dsel, a la metaprog constexpr...

% TODO - on en vient a la mesure du compile time

% TODO - Objectifs de la these: on se creuse sur tout ca...

The objective of this thesis is to develop and assess new ways to write
\cpp metaprograms that enable better compile time performance, as well as
better maintainability by using


% TODO   - C'est complique la programmation parallele (3 vendeurs de \glspl{gpu}???)
% TODO     du coup on fait des outils qui generent du code parallele
% TODO   - Exposer la problematique des methodes de bench pour la meta + la repro
% TODO - Detail du plan

\end{document}
